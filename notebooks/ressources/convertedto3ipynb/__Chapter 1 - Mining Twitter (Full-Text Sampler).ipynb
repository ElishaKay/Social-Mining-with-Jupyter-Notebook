{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1. Mining Twitter: Exploring Trending Topics, Discovering What People Are Talking About, and More"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "<p>This content is a full-text excerpt from <a href=\"http://bit.ly/135dHfs\" target=\"_blank\">Mining the Social Web (2nd Edition)</a> that has been minimally converted to IPython Notebook format so that you can interactively run the example code as you read the book. The purpose of this offering is to determine if there is sufficient interest to offer the remainder of the entire book as a collection of IPython Notebooks (as a standard distribution format that's in addition to PDF, Kindle, etc.) based on feedback from you.</p>\n",
    "<p>If you would like to see the full-text of this book (or other books like it) offered in a native IPython Notebook format, tweet something like <em>\"@OReillyMedia: Please distribute @SocialWebMining in IPython Notebook format\"</em> so that both O'Reilly Media and the author receive your feedback. Alternatively, contact O'Reilly Media using the link above. Thanks!</p>\n",
    "<p>\n",
    "You can also view this sampler chapter in O'Reilly's new <a href=\"http://chimera.labs.oreilly.com/books/1234000001583/index.html\" target=\"_blank\">Chimera ebook reader</a> or <a href=\"http://bit.ly/135dHfs\" target=\"_blank\">download a PDF</a>.\n",
    "</p>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter kicks off our journey of mining the social web with\n",
    "  Twitter, a rich source of social data that is a great starting point for\n",
    "  social web mining because of its inherent openness for public consumption,\n",
    "  clean and well-documented API, rich developer tooling, and broad appeal to\n",
    "  users from every walk of life. Twitter data is particularly interesting\n",
    "  because tweets happen at the \"speed of thought\" and are available for\n",
    "  consumption as they happen in near real time, represent the broadest\n",
    "  cross-section of society at an international level, and are so inherently\n",
    "  multifaceted. Tweets and Twitter's \"following\" mechanism link people in a variety of ways, ranging from short\n",
    "  (but often meaningful) conversational dialogues to interest graphs that\n",
    "  connect people and the things that they care about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is the first chapter, we'll take our time acclimating to\n",
    "  our journey in social web mining. However, given that Twitter data is so\n",
    "  accessible and open to public scrutiny, Chapter&#160;9, <em>Twitter Cookbook</em>\n",
    "  further elaborates on the broad number of data mining possibilities by\n",
    "  providing a terse collection of recipes in a convenient problem/solution\n",
    "  format that can be easily manipulated and readily applied to a wide range of\n",
    "  problems. You'll also be able to apply concepts from future chapters to\n",
    "  Twitter data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote><div><strong>Note:</strong></div><p>Always get the latest bug-fixed source code for this chapter (and\n",
    "    every other chapter) online at <a class=\"ulink\" href=\"http://bit.ly/MiningTheSocialWeb2E\" target=\"\\_top\">http://bit.ly/MiningTheSocialWeb2E</a>.\n",
    "    Be sure to also take advantage of this book's virtual machine experience,\n",
    "    as described in Appendix&#160;A, <em>Information About This Book's Virtual Machine Experience</em>, to maximize your enjoyment of the\n",
    "    sample code.</p></blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, we'll ease into the process of getting situated\n",
    "    with a minimal (but effective) development environment with Python, survey\n",
    "    Twitter's API, and distill some analytical insights from tweets using\n",
    "    frequency analysis. Topics that you'll learn about in this chapter\n",
    "    include:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul class=\"itemizedlist\">\n",
    "            <li class=\"listitem\">\n",
    "              <p>Twitter's developer platform and how to make API requests</p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>Tweet metadata and how to use it</p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>Extracting entities such as user mentions, hashtags, and URLs\n",
    "        from tweets</p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>Techniques for performing frequency analysis with Python</p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>Plotting histograms of Twitter data with IPython Notebook</p>\n",
    "            </li>\n",
    "          </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Is Twitter All the Rage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most chapters won't open with a reflective discussion, but since this is\n",
    "    the first chapter of the book and introduces a social website that is\n",
    "    often misunderstood, it seems appropriate to take a moment to examine\n",
    "    Twitter at a fundamental level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would you define Twitter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to answer this question, but let's consider it\n",
    "    from an overarching angle that addresses some fundamental aspects of our\n",
    "    shared humanity that any technology needs to account for in order to be\n",
    "    useful and successful. After all, the purpose of technology is to enhance\n",
    "    our human experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As humans, what are some things that we want that technology might\n",
    "    help us to get?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul class=\"itemizedlist\">\n",
    "            <li class=\"listitem\">\n",
    "              <p>We want to be heard.</p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>We want to satisfy our curiosity.</p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>We want it easy.</p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>We want it now.</p>\n",
    "            </li>\n",
    "          </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of the current discussion, these are just a few\n",
    "    observations that are generally true of humanity. We have a deeply rooted\n",
    "    need to share our ideas and experiences, which gives us the ability to\n",
    "    connect with other people, to be heard, and to feel a sense of worth and\n",
    "    importance. We are curious about the world around us and how to organize\n",
    "    and manipulate it, and we use communication to share our observations, ask\n",
    "    questions, and engage with other people in meaningful dialogues about our\n",
    "    quandaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last two bullet points highlight our inherent intolerance to\n",
    "    friction. Ideally, we don't want to have to work any harder than is\n",
    "    absolutely necessary to satisfy our curiosity or get any particular job\n",
    "    done; we'd rather be doing \"something else\" or moving on to the next thing\n",
    "    because our time on this planet is so precious and short. Along similar\n",
    "    lines, we want things <span class=\"emphasis\"><em>now</em></span> and tend to be impatient\n",
    "    when actual progress doesn't happen at the speed of our own\n",
    "    thought."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to describe Twitter is as a microblogging service that\n",
    "    allows people to communicate with short, 140-character messages that\n",
    "    roughly correspond to thoughts or ideas. In that regard, you could think\n",
    "    of Twitter as being akin to a free, high-speed, global text-messaging\n",
    "    service. In other words, it's a glorified piece of valuable infrastructure\n",
    "    that enables rapid and easy communication. However, that’s not all of the\n",
    "    story. It doesn't adequately address our inherent curiosity and the value\n",
    "    proposition that emerges when you have over <a class=\"ulink\" href=\"http://bit.ly/1a1kNXR\" target=\"\\_top\">500 million curious people registered, with\n",
    "    over 100 million of them actively engaging</a> their curiosity on a\n",
    "    regular monthly basis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the macro-level possibilities for marketing and\n",
    "    advertising—which are always lucrative with a user base of that size—it's\n",
    "    the underlying network dynamics that created the gravity for such a user\n",
    "    base to emerge that are truly interesting, and that's why Twitter is all\n",
    "    the rage. While the communication bus that enables users to share short\n",
    "    quips at the speed of thought may be a <span class=\"emphasis\"><em>necessary</em></span>\n",
    "    condition for viral adoption and sustained engagement on the Twitter\n",
    "    platform, it's not a <span class=\"emphasis\"><em>sufficient</em></span> condition. The extra\n",
    "    ingredient that makes it sufficient is that Twitter's asymmetric\n",
    "    following model satisfies our curiosity. It is the\n",
    "    asymmetric following model that casts Twitter as more of an interest graph\n",
    "    than a social network, and the APIs that provide just enough of a\n",
    "    framework for structure and self-organizing behavior to emerge from the\n",
    "    chaos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, whereas some social websites like Facebook and\n",
    "    LinkedIn require the mutual acceptance of a connection between users\n",
    "    (which usually implies a real-world connection of some kind), Twitter's\n",
    "    relationship model allows you to keep up with the latest happenings of\n",
    "    <span class=\"emphasis\"><em>any</em></span> other user, even though that other user may not\n",
    "    choose to follow you back or even know that you exist. Twitter's\n",
    "    <span class=\"emphasis\"><em>following</em></span> model is simple but exploits a fundamental\n",
    "    aspect of what makes us human: our curiosity. Whether it be an infatuation\n",
    "    with celebrity gossip, an urge to keep up with a favorite sports team, a\n",
    "    keen interest in a particular political topic, or a desire to connect with\n",
    "    someone new, Twitter provides you with boundless opportunities to satisfy\n",
    "    your curiosity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think of an <span class=\"emphasis\"><em>interest graph</em></span> as a way of modeling\n",
    "    connections between people and their arbitrary interests. Interest graphs\n",
    "    provide a profound number of possibilities in the data mining realm that\n",
    "    primarily involve measuring correlations between things for the objective\n",
    "    of making intelligent recommendations and other applications in machine\n",
    "    learning. For example, you could use an interest graph to measure\n",
    "    correlations and make recommendations ranging from whom to follow on\n",
    "    Twitter to what to purchase online to whom you should date. To illustrate\n",
    "    the notion of Twitter as an interest graph, consider that a Twitter user\n",
    "    need not be a real person; it very well could be a person, but it could\n",
    "    also be an inanimate object, a company, a musical group, an imaginary\n",
    "    persona, an impersonation of someone (living or dead), or just about\n",
    "    anything else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the <a class=\"ulink\" href=\"http://bit.ly/1a1kQD1\" target=\"\\_top\">@HomerJSimpson</a> account is the official\n",
    "    account for Homer Simpson, a popular character from <span class=\"emphasis\"><em>The\n",
    "    Simpsons</em></span> television show. Although Homer Simpson isn't a real\n",
    "    person, he's a well-known personality throughout the world, and the\n",
    "    @HomerJSimpson Twitter persona acts as an conduit for him (or his\n",
    "    creators, actually) to engage his fans. Likewise, although this book will\n",
    "    probably never reach the popularity of Homer Simpson, <a class=\"ulink\" href=\"http://bit.ly/1a1kHzq\" target=\"\\_top\">@SocialWebMining</a> is its official\n",
    "    Twitter account and provides a means for a community that's interested in\n",
    "    its content to connect and engage on various levels. When you realize that\n",
    "    Twitter enables you to create, connect, and explore a community of\n",
    "    interest for an arbitrary topic of interest, the power of Twitter and the\n",
    "    insights you can gain from mining its data become much more\n",
    "    obvious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is very little governance of what a Twitter account can be aside from the badges on some\n",
    "    accounts that identify celebrities and public figures as \"verified\n",
    "    accounts\" and basic restrictions in Twitter's <a class=\"ulink\" href=\"http://bit.ly/1a1kRXl\" target=\"\\_top\">Terms of Service agreement</a>, which is\n",
    "    required for using the service. It may seem very subtle, but it's an\n",
    "    important distinction from some social websites in which accounts must\n",
    "    correspond to real, living people, businesses, or entities of a similar\n",
    "    nature that fit into a particular taxonomy. Twitter places no particular\n",
    "    restrictions on the persona of an account and relies on self-organizing\n",
    "    behavior such as following relationships and folksonomies that emerge from\n",
    "    the use of hashtags to create a certain kind of order within the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote><div><strong>Sidebar Discussion:</strong></div><div class=\"titlepage\">\n",
    "            <div>\n",
    "              <div>\n",
    "                <div class=\"sidebar-title\">Taxonomies and Folksonomies</div>\n",
    "              </div>\n",
    "            </div>\n",
    "          </div>\n",
    "          <p>A fundamental aspect of human intelligence is the desire to classify things and\n",
    "      derive a hierarchy in which each element &#8220;belongs to&#8221; or is a &#8220;child&#8221; of\n",
    "      a parent element one level higher in the hierarchy. Leaving aside some\n",
    "      of the <a class=\"ulink\" href=\"http://bit.ly/1a1kRXy\" target=\"\\_top\">finer distinctions between a\n",
    "      taxonomy and an ontology</a>, think of a\n",
    "      <span class=\"emphasis\"><em>taxonomy</em></span> as a hierarchical structure like a tree\n",
    "      that classifies elements into particular parent/child relationships,\n",
    "      whereas a <a class=\"ulink\" href=\"http://bit.ly/1a1kU5C\" target=\"\\_top\"><span class=\"emphasis\"><em>folksonomy</em></span></a> (a\n",
    "      term coined around 2004) describes the universe of\n",
    "      collaborative tagging and social indexing efforts that emerge in various\n",
    "      ecosystems of the Web. It&#8217;s a play on words in the sense that it blends\n",
    "      <span class=\"emphasis\"><em>folk</em></span> and <span class=\"emphasis\"><em>taxonomy</em></span>. So, in\n",
    "      essence, a folksonomy is just a fancy way of describing the\n",
    "      decentralized universe of tags that emerges as a mechanism of <span class=\"emphasis\"><em>collective intelligence</em></span>\n",
    "      when you allow people to classify content with labels. One of the things\n",
    "      that's so compelling about the use of hashtags on Twitter is that the\n",
    "      folksonomies that organically emerge act as points of aggregation for\n",
    "      common interests and provide a focused way to explore while still\n",
    "      leaving open the possibility for nearly unbounded serendipity.</p></blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Twitter's API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now having a proper frame of reference for Twitter, let us now\n",
    "    transition our attention to the problem of acquiring and analyzing Twitter\n",
    "    data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamental Twitter Terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter might be described as a real-time, highly social microblogging\n",
    "      service that allows users to post short status updates, called <span class=\"emphasis\"><em>tweets</em></span>, that appear on timelines. Tweets may include one or more\n",
    "      entities in their 140 characters of content and reference one or more\n",
    "      places that map to locations in the real world. An understanding\n",
    "      of users, tweets, and timelines is particularly essential to effective\n",
    "      use of <a class=\"ulink\" href=\"http://bit.ly/1a1kSKQ\" target=\"\\_top\">Twitter's API</a>, so a\n",
    "      brief introduction to these fundamental <a class=\"ulink\" href=\"http://bit.ly/1a1kSL8\" target=\"\\_top\">Twitter\n",
    "      Platform objects</a> is in order before we interact with the API to\n",
    "      fetch some data. We've largely discussed Twitter users and Twitter's\n",
    "      asymmetric following model for relationships thus far, so this section\n",
    "      briefly introduces tweets and timelines in order to round out a general\n",
    "      understanding of the Twitter platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweets are the essence of Twitter, and while they are notionally\n",
    "      thought of as the 140 characters of text content associated with a\n",
    "      user's status update, there's really quite a bit more metadata there than meets the eye. In addition to the\n",
    "      textual content of a tweet itself, tweets come bundled with two\n",
    "      additional pieces of metadata that are of particular note:\n",
    "      <span class=\"emphasis\"><em>entities</em></span> and <span class=\"emphasis\"><em>places</em></span>. Tweet\n",
    "      entities are essentially the user mentions, hashtags, URLs, and media that may be\n",
    "      associated with a tweet, and places are locations in the real world that\n",
    "      may be attached to a tweet. Note that a place may be the actual location\n",
    "      in which a tweet was authored, but it might also be a reference to the\n",
    "      place described in a tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it all a bit more concrete, let's consider a sample tweet\n",
    "      with the following text:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote class=\"blockquote\">\n",
    "              <p>@ptwobrussell is writing @SocialWebMining, 2nd Ed. from his home\n",
    "        office in Franklin, TN. Be \\#social: http://on.fb.me/16WJAf9</p>\n",
    "            </blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tweet is 124 characters long and contains four tweet entities:\n",
    "      the user mentions @ptwobrussell and @SocialWebMining, the hashtag\n",
    "      \\#social, and the URL <a class=\"ulink\" href=\"http://on.fb.me/16WJAf9\" target=\"\\_top\">http://on.fb.me/16WJAf9</a>. Although there is a place called\n",
    "      Franklin, Tennessee that's explicitly mentioned in the tweet, the\n",
    "      <span class=\"emphasis\"><em>places</em></span> metadata associated with the tweet might\n",
    "      include the location in which the tweet was authored, which may or may\n",
    "      not be Franklin, Tennessee. That's a lot of metadata that's packed into\n",
    "      fewer than 140 characters and illustrates just how potent a short quip\n",
    "      can be: it can unambiguously refer to multiple other Twitter users, link\n",
    "      to web pages, and cross-reference topics with hashtags that act as\n",
    "      points of aggregation and horizontally slice through the entire Twitterverse in an easily searchable\n",
    "      fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, <span class=\"emphasis\"><em>timelines</em></span> are the chronologically\n",
    "      sorted collections of tweets. Abstractly, you might say that a timeline\n",
    "      is any particular collection of tweets displayed in chronological order;\n",
    "      however, you'll commonly see a couple of timelines that are particularly\n",
    "      noteworthy. From the perspective of an arbitrary Twitter user, the\n",
    "      <span class=\"emphasis\"><em>home timeline</em></span> is the view that you see when you log into your account and look\n",
    "      at all of the tweets from users that you are following, whereas a particular <span class=\"emphasis\"><em>user timeline</em></span> is a\n",
    "      collection of tweets only from a certain user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, when you log into your Twitter account, your home timeline is located at\n",
    "      <a class=\"ulink\" href=\"http://bit.ly/1a1kT1v\" target=\"\\_top\">https://twitter.com</a>. The URL for any\n",
    "      particular user timeline, however, must be suffixed with a context that\n",
    "      identifies the user, such as <a class=\"ulink\" href=\"http://bit.ly/1a1kT1E\" target=\"\\_top\">https://twitter.com/SocialWebMining</a>.\n",
    "      If you're interested in seeing what a particular user's home timeline\n",
    "      looks like from that user's perspective, you can access it with the\n",
    "      additional <span class=\"emphasis\"><em>following</em></span> suffix appended to the URL.\n",
    "      For example, what Tim O'Reilly sees on his home timeline when he logs\n",
    "      into Twitter is accessible at <a class=\"ulink\" href=\"http://bit.ly/1a1kV9x\" target=\"\\_top\">https://twitter.com/timoreilly/following</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An application like TweetDeck provides several customizable views into the\n",
    "      tumultuous landscape of tweets, as shown in Figure&#160;1.1, &#8220;TweetDeck provides a highly customizable user interface that\n",
    "        can be helpful for analyzing what is happening on Twitter and\n",
    "        demonstrates the kind of data that you have access to through the\n",
    "        Twitter API&#8221;, and is worth trying out if you haven't journeyed\n",
    "      far beyond the Twitter.com user interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"figure-title\">Figure&#160;1.1.&#160;TweetDeck provides a highly customizable user interface that\n",
    "        can be helpful for analyzing what is happening on Twitter and\n",
    "        demonstrates the kind of data that you have access to through the\n",
    "        Twitter API</div>\n",
    "            <div class=\"figure-contents\">\n",
    "              <div class=\"mediaobject\">\n",
    "                <img alt=\"TweetDeck provides a highly customizable user interface that can be helpful for analyzing what is happening on Twitter and demonstrates the kind of data that you have access to through the Twitter API\" src=\"files/resources/sampler-images/images/mswb_0101.png\" />\n",
    "              </div>\n",
    "            </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas timelines are collections of tweets with relatively low\n",
    "      velocity, <span class=\"emphasis\"><em>streams</em></span> are samples of public tweets\n",
    "      flowing through Twitter in realtime. The <span class=\"emphasis\"><em>public\n",
    "      firehose</em></span> of all tweets has been known to <a class=\"ulink\" href=\"http://bit.ly/1a1kV9N\" target=\"\\_top\">peak at hundreds of thousands of tweets per\n",
    "      minute</a> during events with particularly wide interest, such as\n",
    "      presidential debates. Twitter's public firehose emits far too much data\n",
    "      to consider for the scope of this book and presents interesting\n",
    "      engineering challenges, which is at least one of the reasons that\n",
    "      various third-party commercial vendors have partnered with Twitter to\n",
    "      bring the firehose to the masses in a more consumable fashion. That\n",
    "      said, <a class=\"ulink\" href=\"http://bit.ly/1a1kVq7\" target=\"\\_top\">a small random sample of the\n",
    "      public timeline</a> is available that provides filterable access to enough public data for API\n",
    "      developers to develop powerful applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remainder of this chapter and Part II of this book assume that\n",
    "      you have a Twitter account, which is required for API access. If you\n",
    "      don't have an account already, take a moment to create onem and then review Twitter&#8217;s liberal <a class=\"ulink\" href=\"http://bit.ly/1a1kWKB\" target=\"\\_top\">terms of service</a>, <a class=\"ulink\" href=\"http://bit.ly/1a1kSKQ\" target=\"\\_top\">API documentation</a>, and <a class=\"ulink\" href=\"http://bit.ly/1a1kX1a\" target=\"\\_top\">Developer Rules of the Road</a>. The\n",
    "      sample code for this chapter and Part II of the book generally don't\n",
    "      require you to have any friends or followers of your own, but some of\n",
    "      the examples in Part II will be a lot more interesting and fun if you\n",
    "      have an active account with a handful of friends and followers that you\n",
    "      can use as a basis for social web mining. If you don't have an active\n",
    "      account, now would be a good time to get plugged in and start priming\n",
    "      your account for the data mining fun to come."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Twitter API Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter has taken great care to craft an elegantly simple <a class=\"ulink\" href=\"http://bit.ly/1a1kVX5\" target=\"\\_top\">RESTful</a>\n",
    "      API that is intuitive and easy to use. Even so, there are great\n",
    "      libraries available to further mitigate the work involved in making API\n",
    "      requests. A particularly beautiful Python package that wraps the Twitter API and\n",
    "      mimics the public API semantics almost one-to-one is <code class=\"literal\">twitter</code>. Like most other Python packages, you\n",
    "      can install it with <code class=\"literal\">pip</code> by typing <strong class=\"userinput\"><code>pip install\n",
    "      twitter</code></strong> in a terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote><div><strong>Note:</strong></div><p>See Appendix&#160;C, <em>Python and IPython Notebook Tips &amp; Tricks</em> for instructions on how to install\n",
    "        <code class=\"literal\">pip</code>.</p></blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote><div><strong>Sidebar Discussion:</strong></div><div class=\"titlepage\">\n",
    "              <div>\n",
    "                <div>\n",
    "                  <div class=\"sidebar-title\">Python Tip: Harnessing pydoc for Effective Help During\n",
    "        Development</div>\n",
    "                </div>\n",
    "              </div>\n",
    "            </div>\n",
    "            <p>We&#8217;ll work though some examples that illustrate the use of the\n",
    "        <code class=\"literal\">twitter</code> package, but just in case\n",
    "        you're ever in a situation where you need some help (and you will be),\n",
    "        it's worth remembering that you can always skim the documentation for\n",
    "        a package (its <a class=\"ulink\" href=\"http://bit.ly/1a1kVXg\" target=\"\\_top\"><code class=\"literal\">pydoc</code></a>) in a few different ways. Outside of a Python shell, running\n",
    "        <code class=\"literal\">pydoc</code> in your terminal on a package\n",
    "        in your <code class=\"literal\">PYTHONPATH</code> is a\n",
    "        nice option. For example, on a Linux or Mac system, you can simply\n",
    "        type <strong class=\"userinput\"><code>pydoc twitter</code></strong> in a\n",
    "        terminal to get the package-level documentation, whereas <strong class=\"userinput\"><code>pydoc twitter.Twitter</code></strong> provides\n",
    "        documentation on the <code class=\"code\">Twitter</code> class included with that\n",
    "        package. On Windows systems, you can get the same information, albeit\n",
    "        in a slightly different way, by executing <code class=\"literal\">pydoc</code> as a package. Typing <strong class=\"userinput\"><code>python -mpydoc twitter.Twitter</code></strong>, for\n",
    "        example, would provide information on the <code class=\"literal\">twitter.Twitter</code> class. If you find yourself\n",
    "        reviewing the documentation for certain modules often, you can elect\n",
    "        to pass the <code class=\"literal\">-w</code> option to\n",
    "        <code class=\"code\">pydoc</code> and write out an HTML page that you can save and\n",
    "        bookmark in your browser.</p>\n",
    "            <p>However, more than likely, you'll be in the middle of a working\n",
    "        session when you need some help. The built-in <code class=\"literal\">help</code>\n",
    "        function accepts a package or class name and is useful for an ordinary\n",
    "        Python shell, whereas <a class=\"ulink\" href=\"http://bit.ly/1a1kXyf\" target=\"\\_top\">IPython</a> users can suffix a package\n",
    "        or class name with a question mark to view inline help. For example,\n",
    "        you could type <strong class=\"userinput\"><code>help(twitter)</code></strong> or\n",
    "        <strong class=\"userinput\"><code>help(twitter.Twitter)</code></strong> in a\n",
    "        regular Python interpreter, while you could use the shortcut\n",
    "        <strong class=\"userinput\"><code>twitter?</code></strong> or <strong class=\"userinput\"><code>twitter.Twitter?</code></strong> in IPython or IPython\n",
    "        Notebook.</p>\n",
    "            <p>It is highly recommended that you adopt IPython as your standard\n",
    "        Python shell when working outside of IPython Notebook because of the\n",
    "        various convenience functions, such as tab completion, session\n",
    "        history, and <a class=\"ulink\" href=\"http://bit.ly/1a1kXyf\" target=\"\\_top\">\"magic\n",
    "        functions,\"</a> that it offers. Recall that Appendix&#160;A, <em>Information About This Book's Virtual Machine Experience</em> provides minimal details on getting oriented with\n",
    "        recommended developer tools such as IPython.</p></blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote><div><strong>Note:</strong></div><p>We'll opt to make programmatic API requests with Python, because\n",
    "        the <code class=\"literal\">twitter</code> package so elegantly\n",
    "        mimics the RESTful API. If you're interested in seeing the raw\n",
    "        requests that you could make with HTTP or exploring the API in a more\n",
    "        interactive manner, however, check out the <a class=\"ulink\" href=\"http://bit.ly/1a1kWui\" target=\"\\_top\">developer console</a> or the\n",
    "        command-line tool <a class=\"ulink\" href=\"http://bit.ly/1a1kZq1\" target=\"\\_top\">Twurl</a>.</p></blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you can make any API requests to Twitter, you'll need to\n",
    "      create an application at <a class=\"ulink\" href=\"http://bit.ly/1a1kYlS\" target=\"\\_top\">https://dev.twitter.com/apps</a>.\n",
    "      Creating an application is the standard way for developers to gain API\n",
    "      access and for Twitter to monitor and interact with third-party platform\n",
    "      developers as needed. The process for creating an application is pretty\n",
    "      standard, and all that's needed is read-only access to the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the present context, <span class=\"emphasis\"><em>you</em></span> are creating an app that you are going to authorize to access\n",
    "      <span class=\"emphasis\"><em>your</em></span> account data, so this might seem a bit\n",
    "      roundabout; why not just plug in your username and password to access\n",
    "      the API? While that approach might work fine for\n",
    "      <span class=\"emphasis\"><em>you</em></span>, a third party such as a friend or colleague\n",
    "      probably wouldn't feel comfortable forking over a username/password\n",
    "      combination in order to enjoy the same insights from\n",
    "      <span class=\"emphasis\"><em>your</em></span> app. Giving up credentials is never a sound\n",
    "      practice. Fortunately, some smart people recognized this problem years ago, and now there's a\n",
    "      standardized protocol called <a class=\"ulink\" href=\"http://bit.ly/1a1kZWN\" target=\"\\_top\">OAuth</a> (short for Open Authorization)\n",
    "      that works for these kinds of situations in a generalized way for the\n",
    "      broader social web. The protocol is a social web standard at this\n",
    "      point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you remember nothing else from this tangent, just remember that\n",
    "      OAuth is a means of allowing users to authorize third-party applications\n",
    "      to access their account data without needing to share sensitive\n",
    "      information like a password. Appendix&#160;B, <em>OAuth Primer</em> provides a slightly\n",
    "      broader overview of how OAuth works if you're interested, and <a class=\"ulink\" href=\"http://bit.ly/1a1kZWW\" target=\"\\_top\">Twitter's OAuth documentation</a> offers\n",
    "      specific details about its particular implementation.<sup>[1]</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity of development, the key pieces of information that\n",
    "      you'll need to take away from your newly created application's settings\n",
    "      are its consumer key, consumer secret, access token, and access\n",
    "      token secret. In tandem, these four credentials provide everything that\n",
    "      an application would ultimately be getting to authorize itself through a\n",
    "      series of redirects involving the user granting authorization, so treat\n",
    "      them with the same sensitivity that you would a password."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote><div><strong>Note:</strong></div><p>See Appendix&#160;B, <em>OAuth Primer</em> for details on implementing an OAuth\n",
    "        2.0 flow that you would need to build an application that requires an\n",
    "        arbitrary user to authorize it to access account data.</p></blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure&#160;1.2, &#8220;Create a new Twitter application to get OAuth credentials and\n",
    "        API access at https://dev.twitter.com/apps;\n",
    "        the four (blurred) OAuth fields are what you'll use to make API calls\n",
    "        to Twitter's API&#8221; shows the context of\n",
    "      retrieving these credentials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"figure-title\">Figure&#160;1.2.&#160;Create a new Twitter application to get OAuth credentials and\n",
    "        API access at <a class=\"ulink\" href=\"https://dev.twitter.com/apps\" target=\"\\_top\">https://dev.twitter.com/apps</a>;\n",
    "        the four (blurred) OAuth fields are what you'll use to make API calls\n",
    "        to Twitter's API</div>\n",
    "            <div class=\"figure-contents\">\n",
    "              <div class=\"mediaobject\">\n",
    "                <img alt=\"Create a new Twitter application to get OAuth credentials and API access at https://dev.twitter.com/apps; the four (blurred) OAuth fields are what you'll use to make API calls to Twitter's API\" src=\"files/resources/sampler-images/images/mswb_0102.png\" />\n",
    "              </div>\n",
    "            </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without further ado, let’s create an authenticated connection to\n",
    "      Twitter's API and find out what people are talking about by inspecting\n",
    "      the trends available to us through the <a class=\"ulink\" href=\"http://bit.ly/1a1kYSQ\" target=\"\\_top\"><code class=\"literal\">GET trends/place</code>\n",
    "      resource</a>. While you're at it, go ahead and bookmark the <a class=\"ulink\" href=\"http://bit.ly/1a1kSKQ\" target=\"\\_top\">official API documentation</a> as well\n",
    "      as the <a class=\"ulink\" href=\"http://bit.ly/1a1kZ9i\" target=\"\\_top\">REST API v1.1\n",
    "      resources</a>, because you'll be referencing them regularly as you\n",
    "      learn the ropes of the developer-facing side of the Twitterverse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote><div><strong>Note:</strong></div><p>As of March 2013, Twitter's API operates at version 1.1 and is\n",
    "          significantly different in a few areas from the previous v1 API that\n",
    "          you may have encountered. Version 1 of the API passed through a\n",
    "          deprecation cycle of approximately six months and is no longer\n",
    "          operational. All sample code in this book presumes version 1.1 of\n",
    "          the API.</p></blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s fire up IPython Notebook and initiate a search. Follow along\n",
    "      with Example&#160;1.1, &#8220;Authorizing an application to access Twitter account\n",
    "        data&#8221; by substituting your own\n",
    "      account credentials into the variables at the beginning of the code\n",
    "      example and execute the call to create an instance of the Twitter API.\n",
    "      The code works by using your OAuth credentials to create an object\n",
    "      called <code class=\"literal\">auth</code> that represents your\n",
    "      OAuth authorization, which can then be passed to a class called <code class=\"literal\">Twitter</code> that is capable of issuing queries to\n",
    "      Twitter's API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1.1. Authorizing an application to access Twitter account data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<twitter.api.Twitter object at 0x7f68c7604780>\n"
     ]
    }
   ],
   "source": [
    "import twitter\n",
    "\n",
    "# XXX: Go to http://dev.twitter.com/apps/new to create an app and get values\n",
    "# for these credentials, which you'll need to provide in place of these\n",
    "# empty string values that are defined as placeholders.\n",
    "# See https://dev.twitter.com/docs/auth/oauth for more information \n",
    "# on Twitter's OAuth implementation.\n",
    "\n",
    "CONSUMER_KEY = 'IlsGJxtQuYE9moHNGBwgbvuG7'\n",
    "CONSUMER_SECRET = 'bNSDW0x8QXw0QPHwJEAKhbhyqxWDlZOqdGh4JUY6Z6ftCzL9Nk'\n",
    "OAUTH_TOKEN = '864787814138949632-GcHCAZ1pfbY2irVKbDfqcoRno3InFpf'\n",
    "OAUTH_TOKEN_SECRET = 'zp0OoZZFRw2TNlHeLkaC8TKGwNK9TjC1iT19zYYKUxBl1'\n",
    "\n",
    "auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                           CONSUMER_KEY, CONSUMER_SECRET)\n",
    "\n",
    "twitter_api = twitter.Twitter(auth=auth)\n",
    "\n",
    "# Nothing to see by displaying twitter_api except that it's now a\n",
    "# defined variable\n",
    "\n",
    "print(twitter_api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of this example should simply display an unambiguous\n",
    "      representation of the <code class=\"literal\">twitter\\_api</code>\n",
    "      object that we've constructed, such as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code><code class=\"literal\">&lt;twitter.api.Twitter object at 0x39d9b50&gt;</code></code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates that we've successfully used OAuth credentials to\n",
    "      gain authorization to query Twitter's API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Trending Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an authorized API connection in place, you can now issue a\n",
    "      request. Example&#160;1.2, &#8220;Retrieving trends&#8221; demonstrates how to\n",
    "      ask Twitter for the topics that are currently trending worldwide, but\n",
    "      keep in mind that the API can easily be parameterized to constrain the\n",
    "      topics to more specific locales if you feel inclined to try out some of\n",
    "      the possibilities. The device for constraining queries is via <a class=\"ulink\" href=\"http://yhoo.it/1a1kZ9u\" target=\"\\_top\">Yahoo!\n",
    "      GeoPlanet&#8217;s</a> Where On Earth (WOE) ID system, which is an API unto\n",
    "      itself that aims to provide a way to map a unique identifier to any\n",
    "      named place on Earth (or theoretically, even in a virtual world). If you\n",
    "      haven't already, go ahead and try out the example that collects a set of\n",
    "      trends for both the entire world and just the United States."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1.2. Retrieving trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'trends': [{'name': '#استراليا_سوريا', 'url': 'http://twitter.com/search?q=%23%D8%A7%D8%B3%D8%AA%D8%B1%D8%A7%D9%84%D9%8A%D8%A7_%D8%B3%D9%88%D8%B1%D9%8A%D8%A7', 'promoted_content': None, 'query': '%23%D8%A7%D8%B3%D8%AA%D8%B1%D8%A7%D9%84%D9%8A%D8%A7_%D8%B3%D9%88%D8%B1%D9%8A%D8%A7', 'tweet_volume': 248050}, {'name': '#WorldMentalHealthDay', 'url': 'http://twitter.com/search?q=%23WorldMentalHealthDay', 'promoted_content': None, 'query': '%23WorldMentalHealthDay', 'tweet_volume': 157194}, {'name': '#AUSvSYR', 'url': 'http://twitter.com/search?q=%23AUSvSYR', 'promoted_content': None, 'query': '%23AUSvSYR', 'tweet_volume': 29068}, {'name': '#10Oct', 'url': 'http://twitter.com/search?q=%2310Oct', 'promoted_content': None, 'query': '%2310Oct', 'tweet_volume': 34100}, {'name': '#FelizMartes', 'url': 'http://twitter.com/search?q=%23FelizMartes', 'promoted_content': None, 'query': '%23FelizMartes', 'tweet_volume': 29009}, {'name': 'فراس الخطيب', 'url': 'http://twitter.com/search?q=%22%D9%81%D8%B1%D8%A7%D8%B3+%D8%A7%D9%84%D8%AE%D8%B7%D9%8A%D8%A8%22', 'promoted_content': None, 'query': '%22%D9%81%D8%B1%D8%A7%D8%B3+%D8%A7%D9%84%D8%AE%D8%B7%D9%8A%D8%A8%22', 'tweet_volume': None}, {'name': 'ハイチ', 'url': 'http://twitter.com/search?q=%E3%83%8F%E3%82%A4%E3%83%81', 'promoted_content': None, 'query': '%E3%83%8F%E3%82%A4%E3%83%81', 'tweet_volume': 32174}, {'name': 'تيم كاهيل', 'url': 'http://twitter.com/search?q=%22%D8%AA%D9%8A%D9%85+%D9%83%D8%A7%D9%87%D9%8A%D9%84%22', 'promoted_content': None, 'query': '%22%D8%AA%D9%8A%D9%85+%D9%83%D8%A7%D9%87%D9%8A%D9%84%22', 'tweet_volume': None}, {'name': 'Catalana Occidente', 'url': 'http://twitter.com/search?q=%22Catalana+Occidente%22', 'promoted_content': None, 'query': '%22Catalana+Occidente%22', 'tweet_volume': None}, {'name': 'الاشواط الاضافيه', 'url': 'http://twitter.com/search?q=%22%D8%A7%D9%84%D8%A7%D8%B4%D9%88%D8%A7%D8%B7+%D8%A7%D9%84%D8%A7%D8%B6%D8%A7%D9%81%D9%8A%D9%87%22', 'promoted_content': None, 'query': '%22%D8%A7%D9%84%D8%A7%D8%B4%D9%88%D8%A7%D8%B7+%D8%A7%D9%84%D8%A7%D8%B6%D8%A7%D9%81%D9%8A%D9%87%22', 'tweet_volume': None}, {'name': 'Carmen Sevilla', 'url': 'http://twitter.com/search?q=%22Carmen+Sevilla%22', 'promoted_content': None, 'query': '%22Carmen+Sevilla%22', 'tweet_volume': None}, {'name': '2-1 a Siria', 'url': 'http://twitter.com/search?q=%222-1+a+Siria%22', 'promoted_content': None, 'query': '%222-1+a+Siria%22', 'tweet_volume': None}, {'name': '#regeerakkoord', 'url': 'http://twitter.com/search?q=%23regeerakkoord', 'promoted_content': None, 'query': '%23regeerakkoord', 'tweet_volume': None}, {'name': '#شيرين_في_الرياض', 'url': 'http://twitter.com/search?q=%23%D8%B4%D9%8A%D8%B1%D9%8A%D9%86_%D9%81%D9%8A_%D8%A7%D9%84%D8%B1%D9%8A%D8%A7%D8%B6', 'promoted_content': None, 'query': '%23%D8%B4%D9%8A%D8%B1%D9%8A%D9%86_%D9%81%D9%8A_%D8%A7%D9%84%D8%B1%D9%8A%D8%A7%D8%B6', 'tweet_volume': 19839}, {'name': '#DiaMundialSaludMental', 'url': 'http://twitter.com/search?q=%23DiaMundialSaludMental', 'promoted_content': None, 'query': '%23DiaMundialSaludMental', 'tweet_volume': None}, {'name': '#DurbanStorm', 'url': 'http://twitter.com/search?q=%23DurbanStorm', 'promoted_content': None, 'query': '%23DurbanStorm', 'tweet_volume': 17761}, {'name': '#DNA9thWin', 'url': 'http://twitter.com/search?q=%23DNA9thWin', 'promoted_content': None, 'query': '%23DNA9thWin', 'tweet_volume': None}, {'name': '#AdaLovelaceDay', 'url': 'http://twitter.com/search?q=%23AdaLovelaceDay', 'promoted_content': None, 'query': '%23AdaLovelaceDay', 'tweet_volume': None}, {'name': '#زد_رصيدك8', 'url': 'http://twitter.com/search?q=%23%D8%B2%D8%AF_%D8%B1%D8%B5%D9%8A%D8%AF%D9%838', 'promoted_content': None, 'query': '%23%D8%B2%D8%AF_%D8%B1%D8%B5%D9%8A%D8%AF%D9%838', 'tweet_volume': 25739}, {'name': '#ενας_εξωγηινος_μου_ειπε', 'url': 'http://twitter.com/search?q=%23%CE%B5%CE%BD%CE%B1%CF%82_%CE%B5%CE%BE%CF%89%CE%B3%CE%B7%CE%B9%CE%BD%CE%BF%CF%82_%CE%BC%CE%BF%CF%85_%CE%B5%CE%B9%CF%80%CE%B5', 'promoted_content': None, 'query': '%23%CE%B5%CE%BD%CE%B1%CF%82_%CE%B5%CE%BE%CF%89%CE%B3%CE%B7%CE%B9%CE%BD%CE%BF%CF%82_%CE%BC%CE%BF%CF%85_%CE%B5%CE%B9%CF%80%CE%B5', 'tweet_volume': None}, {'name': '#10EkimKatliamınıUnutmadık', 'url': 'http://twitter.com/search?q=%2310EkimKatliam%C4%B1n%C4%B1Unutmad%C4%B1k', 'promoted_content': None, 'query': '%2310EkimKatliam%C4%B1n%C4%B1Unutmad%C4%B1k', 'tweet_volume': 41175}, {'name': '#SurvivorAU', 'url': 'http://twitter.com/search?q=%23SurvivorAU', 'promoted_content': None, 'query': '%23SurvivorAU', 'tweet_volume': None}, {'name': '#اليوم_العالمي_للصحه_النفسيه', 'url': 'http://twitter.com/search?q=%23%D8%A7%D9%84%D9%8A%D9%88%D9%85_%D8%A7%D9%84%D8%B9%D8%A7%D9%84%D9%85%D9%8A_%D9%84%D9%84%D8%B5%D8%AD%D9%87_%D8%A7%D9%84%D9%86%D9%81%D8%B3%D9%8A%D9%87', 'promoted_content': None, 'query': '%23%D8%A7%D9%84%D9%8A%D9%88%D9%85_%D8%A7%D9%84%D8%B9%D8%A7%D9%84%D9%85%D9%8A_%D9%84%D9%84%D8%B5%D8%AD%D9%87_%D8%A7%D9%84%D9%86%D9%81%D8%B3%D9%8A%D9%87', 'tweet_volume': 12706}, {'name': '#WorldPorridgeDay', 'url': 'http://twitter.com/search?q=%23WorldPorridgeDay', 'promoted_content': None, 'query': '%23WorldPorridgeDay', 'tweet_volume': None}, {'name': '#NUESTW_WHEREYOUAT', 'url': 'http://twitter.com/search?q=%23NUESTW_WHEREYOUAT', 'promoted_content': None, 'query': '%23NUESTW_WHEREYOUAT', 'tweet_volume': 200204}, {'name': '#BedelliAskerlikGeliyor', 'url': 'http://twitter.com/search?q=%23BedelliAskerlikGeliyor', 'promoted_content': None, 'query': '%23BedelliAskerlikGeliyor', 'tweet_volume': 24948}, {'name': '#NiallMondadoriDuomo', 'url': 'http://twitter.com/search?q=%23NiallMondadoriDuomo', 'promoted_content': None, 'query': '%23NiallMondadoriDuomo', 'tweet_volume': None}, {'name': '#fiducia', 'url': 'http://twitter.com/search?q=%23fiducia', 'promoted_content': None, 'query': '%23fiducia', 'tweet_volume': None}, {'name': '#SchoolLunchIn4Words', 'url': 'http://twitter.com/search?q=%23SchoolLunchIn4Words', 'promoted_content': None, 'query': '%23SchoolLunchIn4Words', 'tweet_volume': None}, {'name': '#TuesdayThoughts', 'url': 'http://twitter.com/search?q=%23TuesdayThoughts', 'promoted_content': None, 'query': '%23TuesdayThoughts', 'tweet_volume': 19735}, {'name': '#HUBFORUM', 'url': 'http://twitter.com/search?q=%23HUBFORUM', 'promoted_content': None, 'query': '%23HUBFORUM', 'tweet_volume': None}, {'name': '#Welthundetag', 'url': 'http://twitter.com/search?q=%23Welthundetag', 'promoted_content': None, 'query': '%23Welthundetag', 'tweet_volume': None}, {'name': '#هشتاقك_معنا_ترند_٠٥٠٧٦٦١٤٠٩', 'url': 'http://twitter.com/search?q=%23%D9%87%D8%B4%D8%AA%D8%A7%D9%82%D9%83_%D9%85%D8%B9%D9%86%D8%A7_%D8%AA%D8%B1%D9%86%D8%AF_%D9%A0%D9%A5%D9%A0%D9%A7%D9%A6%D9%A6%D9%A1%D9%A4%D9%A0%D9%A9', 'promoted_content': None, 'query': '%23%D9%87%D8%B4%D8%AA%D8%A7%D9%82%D9%83_%D9%85%D8%B9%D9%86%D8%A7_%D8%AA%D8%B1%D9%86%D8%AF_%D9%A0%D9%A5%D9%A0%D9%A7%D9%A6%D9%A6%D9%A1%D9%A4%D9%A0%D9%A9', 'tweet_volume': None}, {'name': '#SBBMat8', 'url': 'http://twitter.com/search?q=%23SBBMat8', 'promoted_content': None, 'query': '%23SBBMat8', 'tweet_volume': None}, {'name': '#ATodoONada', 'url': 'http://twitter.com/search?q=%23ATodoONada', 'promoted_content': None, 'query': '%23ATodoONada', 'tweet_volume': None}, {'name': '#Monetiza17', 'url': 'http://twitter.com/search?q=%23Monetiza17', 'promoted_content': None, 'query': '%23Monetiza17', 'tweet_volume': None}, {'name': '#TercaDetremuraSDV', 'url': 'http://twitter.com/search?q=%23TercaDetremuraSDV', 'promoted_content': None, 'query': '%23TercaDetremuraSDV', 'tweet_volume': None}, {'name': '#EuQueriaPararDe', 'url': 'http://twitter.com/search?q=%23EuQueriaPararDe', 'promoted_content': None, 'query': '%23EuQueriaPararDe', 'tweet_volume': None}, {'name': '#KeepGoing', 'url': 'http://twitter.com/search?q=%23KeepGoing', 'promoted_content': None, 'query': '%23KeepGoing', 'tweet_volume': 41466}, {'name': '#DvdD17', 'url': 'http://twitter.com/search?q=%23DvdD17', 'promoted_content': None, 'query': '%23DvdD17', 'tweet_volume': None}, {'name': '#WildflowerKarma', 'url': 'http://twitter.com/search?q=%23WildflowerKarma', 'promoted_content': None, 'query': '%23WildflowerKarma', 'tweet_volume': None}, {'name': '#charitytuesday', 'url': 'http://twitter.com/search?q=%23charitytuesday', 'promoted_content': None, 'query': '%23charitytuesday', 'tweet_volume': None}, {'name': '#Budget18', 'url': 'http://twitter.com/search?q=%23Budget18', 'promoted_content': None, 'query': '%23Budget18', 'tweet_volume': None}, {'name': '#October11SevenSundays', 'url': 'http://twitter.com/search?q=%23October11SevenSundays', 'promoted_content': None, 'query': '%23October11SevenSundays', 'tweet_volume': 65697}, {'name': '#مغرد_يقذف_السعوديات', 'url': 'http://twitter.com/search?q=%23%D9%85%D8%BA%D8%B1%D8%AF_%D9%8A%D9%82%D8%B0%D9%81_%D8%A7%D9%84%D8%B3%D8%B9%D9%88%D8%AF%D9%8A%D8%A7%D8%AA', 'promoted_content': None, 'query': '%23%D9%85%D8%BA%D8%B1%D8%AF_%D9%8A%D9%82%D8%B0%D9%81_%D8%A7%D9%84%D8%B3%D8%B9%D9%88%D8%AF%D9%8A%D8%A7%D8%AA', 'tweet_volume': 64806}, {'name': '#TekSözüm', 'url': 'http://twitter.com/search?q=%23TekS%C3%B6z%C3%BCm', 'promoted_content': None, 'query': '%23TekS%C3%B6z%C3%BCm', 'tweet_volume': 10288}, {'name': '#10ottobre', 'url': 'http://twitter.com/search?q=%2310ottobre', 'promoted_content': None, 'query': '%2310ottobre', 'tweet_volume': None}], 'as_of': '2017-10-10T12:02:27Z', 'created_at': '2017-10-10T11:54:19Z', 'locations': [{'name': 'Worldwide', 'woeid': 1}]}]\n",
      "[{'trends': [{'name': '#WorldMentalHealthDay', 'url': 'http://twitter.com/search?q=%23WorldMentalHealthDay', 'promoted_content': None, 'query': '%23WorldMentalHealthDay', 'tweet_volume': 159905}, {'name': '#SchoolLunchIn4Words', 'url': 'http://twitter.com/search?q=%23SchoolLunchIn4Words', 'promoted_content': None, 'query': '%23SchoolLunchIn4Words', 'tweet_volume': None}, {'name': '#TuesdayThoughts', 'url': 'http://twitter.com/search?q=%23TuesdayThoughts', 'promoted_content': None, 'query': '%23TuesdayThoughts', 'tweet_volume': 20067}, {'name': 'Tim Cahill', 'url': 'http://twitter.com/search?q=%22Tim+Cahill%22', 'promoted_content': None, 'query': '%22Tim+Cahill%22', 'tweet_volume': 11958}, {'name': 'Deadly California', 'url': 'http://twitter.com/search?q=%22Deadly+California%22', 'promoted_content': None, 'query': '%22Deadly+California%22', 'tweet_volume': None}, {'name': 'Virginia Is for Haters', 'url': 'http://twitter.com/search?q=%22Virginia+Is+for+Haters%22', 'promoted_content': None, 'query': '%22Virginia+Is+for+Haters%22', 'tweet_volume': None}, {'name': '#kiss108jingleball', 'url': 'http://twitter.com/search?q=%23kiss108jingleball', 'promoted_content': None, 'query': '%23kiss108jingleball', 'tweet_volume': None}, {'name': '#MorningJoe', 'url': 'http://twitter.com/search?q=%23MorningJoe', 'promoted_content': None, 'query': '%23MorningJoe', 'tweet_volume': 12260}, {'name': 'Officer Louis Remigio', 'url': 'http://twitter.com/search?q=%22Officer+Louis+Remigio%22', 'promoted_content': None, 'query': '%22Officer+Louis+Remigio%22', 'tweet_volume': None}, {'name': 'Fridtjof Nansen', 'url': 'http://twitter.com/search?q=%22Fridtjof+Nansen%22', 'promoted_content': None, 'query': '%22Fridtjof+Nansen%22', 'tweet_volume': None}, {'name': 'Eliot', 'url': 'http://twitter.com/search?q=Eliot', 'promoted_content': None, 'query': 'Eliot', 'tweet_volume': 14348}, {'name': 'Shirogane', 'url': 'http://twitter.com/search?q=Shirogane', 'promoted_content': None, 'query': 'Shirogane', 'tweet_volume': None}, {'name': 'Iron Banner', 'url': 'http://twitter.com/search?q=%22Iron+Banner%22', 'promoted_content': None, 'query': '%22Iron+Banner%22', 'tweet_volume': None}, {'name': 'SCHOOL DELAYS', 'url': 'http://twitter.com/search?q=%22SCHOOL+DELAYS%22', 'promoted_content': None, 'query': '%22SCHOOL+DELAYS%22', 'tweet_volume': None}, {'name': 'Hollis Daniels', 'url': 'http://twitter.com/search?q=%22Hollis+Daniels%22', 'promoted_content': None, 'query': '%22Hollis+Daniels%22', 'tweet_volume': 10662}, {'name': 'Mike Ditka', 'url': 'http://twitter.com/search?q=%22Mike+Ditka%22', 'promoted_content': None, 'query': '%22Mike+Ditka%22', 'tweet_volume': None}, {'name': 'I-95 NB', 'url': 'http://twitter.com/search?q=%22I-95+NB%22', 'promoted_content': None, 'query': '%22I-95+NB%22', 'tweet_volume': None}, {'name': 'Thelonious Monk', 'url': 'http://twitter.com/search?q=%22Thelonious+Monk%22', 'promoted_content': None, 'query': '%22Thelonious+Monk%22', 'tweet_volume': None}, {'name': \"ESPN's Jemele Hill\", 'url': 'http://twitter.com/search?q=%22ESPN%27s+Jemele+Hill%22', 'promoted_content': None, 'query': '%22ESPN%27s+Jemele+Hill%22', 'tweet_volume': None}, {'name': 'George Clooney', 'url': 'http://twitter.com/search?q=%22George+Clooney%22', 'promoted_content': None, 'query': '%22George+Clooney%22', 'tweet_volume': None}, {'name': 'Magnitude 6.3', 'url': 'http://twitter.com/search?q=%22Magnitude+6.3%22', 'promoted_content': None, 'query': '%22Magnitude+6.3%22', 'tweet_volume': None}, {'name': 'Dense Fog Advisory', 'url': 'http://twitter.com/search?q=%22Dense+Fog+Advisory%22', 'promoted_content': None, 'query': '%22Dense+Fog+Advisory%22', 'tweet_volume': None}, {'name': 'Kobe Steel', 'url': 'http://twitter.com/search?q=%22Kobe+Steel%22', 'promoted_content': None, 'query': '%22Kobe+Steel%22', 'tweet_volume': None}, {'name': 'Indianapolis Colts', 'url': 'http://twitter.com/search?q=%22Indianapolis+Colts%22', 'promoted_content': None, 'query': '%22Indianapolis+Colts%22', 'tweet_volume': None}, {'name': 'He Should Resign Immediately', 'url': 'http://twitter.com/search?q=%22He+Should+Resign+Immediately%22', 'promoted_content': None, 'query': '%22He+Should+Resign+Immediately%22', 'tweet_volume': None}, {'name': 'Turtles All The Way Down', 'url': 'http://twitter.com/search?q=%22Turtles+All+The+Way+Down%22', 'promoted_content': None, 'query': '%22Turtles+All+The+Way+Down%22', 'tweet_volume': None}, {'name': '#TravelTuesday', 'url': 'http://twitter.com/search?q=%23TravelTuesday', 'promoted_content': None, 'query': '%23TravelTuesday', 'tweet_volume': None}, {'name': '#bfc530', 'url': 'http://twitter.com/search?q=%23bfc530', 'promoted_content': None, 'query': '%23bfc530', 'tweet_volume': None}, {'name': '#WhatExesAreGoodFor', 'url': 'http://twitter.com/search?q=%23WhatExesAreGoodFor', 'promoted_content': None, 'query': '%23WhatExesAreGoodFor', 'tweet_volume': None}, {'name': '#TheMarkets17', 'url': 'http://twitter.com/search?q=%23TheMarkets17', 'promoted_content': None, 'query': '%23TheMarkets17', 'tweet_volume': None}, {'name': '#MysteryOREO', 'url': 'http://twitter.com/search?q=%23MysteryOREO', 'promoted_content': None, 'query': '%23MysteryOREO', 'tweet_volume': None}, {'name': '#NLCS', 'url': 'http://twitter.com/search?q=%23NLCS', 'promoted_content': None, 'query': '%23NLCS', 'tweet_volume': 20858}, {'name': '#n4tm', 'url': 'http://twitter.com/search?q=%23n4tm', 'promoted_content': None, 'query': '%23n4tm', 'tweet_volume': None}, {'name': '#TISL', 'url': 'http://twitter.com/search?q=%23TISL', 'promoted_content': None, 'query': '%23TISL', 'tweet_volume': None}, {'name': '#AdaLovelaceDay', 'url': 'http://twitter.com/search?q=%23AdaLovelaceDay', 'promoted_content': None, 'query': '%23AdaLovelaceDay', 'tweet_volume': None}, {'name': '#nxStep', 'url': 'http://twitter.com/search?q=%23nxStep', 'promoted_content': None, 'query': '%23nxStep', 'tweet_volume': None}, {'name': '#GPC2020', 'url': 'http://twitter.com/search?q=%23GPC2020', 'promoted_content': None, 'query': '%23GPC2020', 'tweet_volume': None}, {'name': '#Shoptalkeurope', 'url': 'http://twitter.com/search?q=%23Shoptalkeurope', 'promoted_content': None, 'query': '%23Shoptalkeurope', 'tweet_volume': None}, {'name': '#FIPPCongress', 'url': 'http://twitter.com/search?q=%23FIPPCongress', 'promoted_content': None, 'query': '%23FIPPCongress', 'tweet_volume': None}, {'name': '#Daybreak', 'url': 'http://twitter.com/search?q=%23Daybreak', 'promoted_content': None, 'query': '%23Daybreak', 'tweet_volume': None}, {'name': '#STMFrankfurt', 'url': 'http://twitter.com/search?q=%23STMFrankfurt', 'promoted_content': None, 'query': '%23STMFrankfurt', 'tweet_volume': None}, {'name': '#GMRVA', 'url': 'http://twitter.com/search?q=%23GMRVA', 'promoted_content': None, 'query': '%23GMRVA', 'tweet_volume': None}, {'name': '#WhatILearnedToday', 'url': 'http://twitter.com/search?q=%23WhatILearnedToday', 'promoted_content': None, 'query': '%23WhatILearnedToday', 'tweet_volume': None}, {'name': '#BooksThatAreTasty', 'url': 'http://twitter.com/search?q=%23BooksThatAreTasty', 'promoted_content': None, 'query': '%23BooksThatAreTasty', 'tweet_volume': None}, {'name': '#LendItEurope', 'url': 'http://twitter.com/search?q=%23LendItEurope', 'promoted_content': None, 'query': '%23LendItEurope', 'tweet_volume': None}, {'name': '#liberiadecides', 'url': 'http://twitter.com/search?q=%23liberiadecides', 'promoted_content': None, 'query': '%23liberiadecides', 'tweet_volume': None}, {'name': '#TacoTuesday', 'url': 'http://twitter.com/search?q=%23TacoTuesday', 'promoted_content': None, 'query': '%23TacoTuesday', 'tweet_volume': None}, {'name': '#TJMS', 'url': 'http://twitter.com/search?q=%23TJMS', 'promoted_content': None, 'query': '%23TJMS', 'tweet_volume': None}, {'name': '#NowForum', 'url': 'http://twitter.com/search?q=%23NowForum', 'promoted_content': None, 'query': '%23NowForum', 'tweet_volume': None}, {'name': '#IQTday', 'url': 'http://twitter.com/search?q=%23IQTday', 'promoted_content': None, 'query': '%23IQTday', 'tweet_volume': None}], 'as_of': '2017-10-10T12:02:28Z', 'created_at': '2017-10-10T11:59:11Z', 'locations': [{'name': 'United States', 'woeid': 23424977}]}]\n"
     ]
    }
   ],
   "source": [
    "# The Yahoo! Where On Earth ID for the entire world is 1.\n",
    "# See https://dev.twitter.com/docs/api/1.1/get/trends/place and\n",
    "# http://developer.yahoo.com/geo/geoplanet/\n",
    "\n",
    "WORLD_WOE_ID = 1\n",
    "US_WOE_ID = 23424977\n",
    "\n",
    "# Prefix ID with the underscore for query string parameterization.\n",
    "# Without the underscore, the twitter package appends the ID value\n",
    "# to the URL itself as a special case keyword argument.\n",
    "\n",
    "world_trends = twitter_api.trends.place(_id=WORLD_WOE_ID)\n",
    "us_trends = twitter_api.trends.place(_id=US_WOE_ID)\n",
    "\n",
    "print(world_trends)\n",
    "print\n",
    "print(us_trends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a semireadable response that is a list of Python\n",
    "      dictionaries from the API (as opposed to any kind of error message),\n",
    "      such as the following truncated results, before proceeding further. (In\n",
    "      just a moment, we'll reformat the response to be more easily\n",
    "      readable.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>[{u'created\\_at': u'2013-03-27T11:50:40Z', u'trends': [{u'url': u'http://twitter.com/search?q=%23MentionSomeoneImportantForYou'...</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the sample result contains a URL for a trend\n",
    "      represented as a search query that corresponds to the hashtag\n",
    "      \\#MentionSomeoneImportantForYou, where %23 is the URL encoding for the\n",
    "      hashtag symbol. We'll use this rather benign hashtag throughout the\n",
    "      remainder of the chapter as a unifying theme for examples that follow.\n",
    "      Although a sample data file containing tweets for this hashtag is\n",
    "      available with the book's source code, you'll have much more fun\n",
    "      exploring a topic that's trending at the time you read this as opposed\n",
    "      to following along with a canned topic that is no longer\n",
    "      trending."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pattern for using the <code class=\"code\">twitter</code> module is simple\n",
    "      and predictable: instantiate the <code class=\"code\">Twitter</code> class with an object\n",
    "      chain corresponding to a base URL and then invoke methods on the object\n",
    "      that correspond to URL contexts. For example,\n",
    "      <code class=\"code\">twitter\\_api.</code>\\_<code class=\"code\">trends.place(WORLD\\_WOE\\_ID)</code> initiates an HTTP\n",
    "      call to GET\n",
    "      <span class=\"emphasis\"><em>https://api.twitter.com/1.1/trends/place.json?id=1</em></span>.\n",
    "      Note the URL mapping to the object chain that's constructed with the\n",
    "      <code class=\"literal\">twitter</code> package to make the request\n",
    "      and how query string parameters are passed in as keyword arguments. To\n",
    "      use the <code class=\"literal\">twitter</code> package for arbitrary\n",
    "      API requests, you generally construct the request in that kind of\n",
    "      straightforward manner, with just a couple of minor caveats that we'll\n",
    "      encounter soon enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter imposes <span class=\"emphasis\"><em>rate limits</em></span> on how many requests an application can make to any given API\n",
    "      resource within a given time window. Twitter's <a class=\"ulink\" href=\"http://bit.ly/1a1l257\" target=\"\\_top\">rate limits</a> are well documented, and\n",
    "      each individual API resource also states its particular limits for your\n",
    "      convenience. For example, the API request that we just issued for trends\n",
    "      limits applications to 15 requests per 15-minute window (see Figure&#160;1.3, &#8220;Rate limits for Twitter API resources are identified in the\n",
    "        online documentation for each API call; the particular API resource\n",
    "        shown here allows 15 requests per \"rate limit window,\" which is\n",
    "        currently defined as 15 minutes&#8221;). For more nuanced information on\n",
    "      how Twitter's rate limits work, see <a class=\"ulink\" href=\"http://bit.ly/1a1l2ly\" target=\"\\_top\">REST API Rate\n",
    "      Limiting in v1.1</a>. For the purposes of following along in this\n",
    "      chapter, it's highly unlikely that you'll get rate\n",
    "      limited. &#8220;Making Robust Twitter Requests&#8221; (Example&#160;9.16, &#8220;Making robust Twitter requests&#8221;) will introduce some\n",
    "      techniques demonstrating best practices while working with rate\n",
    "      limits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"figure-title\">Figure&#160;1.3.&#160;Rate limits for Twitter API resources are identified in the\n",
    "        online documentation for each API call; the particular API resource\n",
    "        shown here allows 15 requests per \"rate limit window,\" which is\n",
    "        currently defined as 15 minutes</div>\n",
    "            <div class=\"figure-contents\">\n",
    "              <div class=\"mediaobject\">\n",
    "                <img alt=\"Rate limits for Twitter API resources are identified in the online documentation for each API call; the particular API resource shown here allows 15 requests per &quot;rate limit window,&quot; which is currently defined as 15 minutes\" src=\"files/resources/sampler-images/images/mswb_0103.png\" />\n",
    "              </div>\n",
    "            </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote><div><strong>Note:</strong></div><p>The developer documentation states that the results of a Trends\n",
    "        API query are updated only once every five minutes, so it's not a\n",
    "        judicious use of your efforts or API requests to ask for results more\n",
    "        often than that.</p></blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it hasn't explicitly been stated yet, the semireadable\n",
    "      output from Example&#160;1.2, &#8220;Retrieving trends&#8221; is printed out as\n",
    "      native Python data structures. While an IPython interpreter will \"pretty\n",
    "      print\" the output for you automatically, IPython Notebook and a standard\n",
    "      Python interpreter will not. If you find yourself in these\n",
    "      circumstances, you may find it handy to use the built-in <code class=\"literal\">json</code>\n",
    "      package to force a nicer display, as illustrated in Example&#160;1.3, &#8220;Displaying API responses as pretty-printed JSON&#8221;."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote><div><strong>Note:</strong></div><p><a class=\"ulink\" href=\"http://bit.ly/1a1l2lJ\" target=\"\\_top\">JSON</a> is a data\n",
    "        exchange format that you will encounter on a regular\n",
    "        basis. In a nutshell, JSON provides a way to arbitrarily store maps,\n",
    "        lists, primitives such as numbers and strings, and combinations\n",
    "        thereof. In other words, you can theoretically model just about\n",
    "        anything with JSON should you desire to do so.</p></blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1.3. Displaying API responses as pretty-printed JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      " {\n",
      "  \"trends\": [\n",
      "   {\n",
      "    \"name\": \"#\\u0627\\u0633\\u062a\\u0631\\u0627\\u0644\\u064a\\u0627_\\u0633\\u0648\\u0631\\u064a\\u0627\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23%D8%A7%D8%B3%D8%AA%D8%B1%D8%A7%D9%84%D9%8A%D8%A7_%D8%B3%D9%88%D8%B1%D9%8A%D8%A7\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23%D8%A7%D8%B3%D8%AA%D8%B1%D8%A7%D9%84%D9%8A%D8%A7_%D8%B3%D9%88%D8%B1%D9%8A%D8%A7\",\n",
      "    \"tweet_volume\": 248050\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#WorldMentalHealthDay\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23WorldMentalHealthDay\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23WorldMentalHealthDay\",\n",
      "    \"tweet_volume\": 157194\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#AUSvSYR\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23AUSvSYR\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23AUSvSYR\",\n",
      "    \"tweet_volume\": 29068\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#10Oct\",\n",
      "    \"url\": \"http://twitter.com/search?q=%2310Oct\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%2310Oct\",\n",
      "    \"tweet_volume\": 34100\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#FelizMartes\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23FelizMartes\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23FelizMartes\",\n",
      "    \"tweet_volume\": 29009\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"\\u0641\\u0631\\u0627\\u0633 \\u0627\\u0644\\u062e\\u0637\\u064a\\u0628\",\n",
      "    \"url\": \"http://twitter.com/search?q=%22%D9%81%D8%B1%D8%A7%D8%B3+%D8%A7%D9%84%D8%AE%D8%B7%D9%8A%D8%A8%22\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%22%D9%81%D8%B1%D8%A7%D8%B3+%D8%A7%D9%84%D8%AE%D8%B7%D9%8A%D8%A8%22\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"\\u30cf\\u30a4\\u30c1\",\n",
      "    \"url\": \"http://twitter.com/search?q=%E3%83%8F%E3%82%A4%E3%83%81\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%E3%83%8F%E3%82%A4%E3%83%81\",\n",
      "    \"tweet_volume\": 32174\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"\\u062a\\u064a\\u0645 \\u0643\\u0627\\u0647\\u064a\\u0644\",\n",
      "    \"url\": \"http://twitter.com/search?q=%22%D8%AA%D9%8A%D9%85+%D9%83%D8%A7%D9%87%D9%8A%D9%84%22\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%22%D8%AA%D9%8A%D9%85+%D9%83%D8%A7%D9%87%D9%8A%D9%84%22\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"Catalana Occidente\",\n",
      "    \"url\": \"http://twitter.com/search?q=%22Catalana+Occidente%22\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%22Catalana+Occidente%22\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"\\u0627\\u0644\\u0627\\u0634\\u0648\\u0627\\u0637 \\u0627\\u0644\\u0627\\u0636\\u0627\\u0641\\u064a\\u0647\",\n",
      "    \"url\": \"http://twitter.com/search?q=%22%D8%A7%D9%84%D8%A7%D8%B4%D9%88%D8%A7%D8%B7+%D8%A7%D9%84%D8%A7%D8%B6%D8%A7%D9%81%D9%8A%D9%87%22\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%22%D8%A7%D9%84%D8%A7%D8%B4%D9%88%D8%A7%D8%B7+%D8%A7%D9%84%D8%A7%D8%B6%D8%A7%D9%81%D9%8A%D9%87%22\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"Carmen Sevilla\",\n",
      "    \"url\": \"http://twitter.com/search?q=%22Carmen+Sevilla%22\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%22Carmen+Sevilla%22\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"2-1 a Siria\",\n",
      "    \"url\": \"http://twitter.com/search?q=%222-1+a+Siria%22\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%222-1+a+Siria%22\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#regeerakkoord\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23regeerakkoord\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23regeerakkoord\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#\\u0634\\u064a\\u0631\\u064a\\u0646_\\u0641\\u064a_\\u0627\\u0644\\u0631\\u064a\\u0627\\u0636\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23%D8%B4%D9%8A%D8%B1%D9%8A%D9%86_%D9%81%D9%8A_%D8%A7%D9%84%D8%B1%D9%8A%D8%A7%D8%B6\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23%D8%B4%D9%8A%D8%B1%D9%8A%D9%86_%D9%81%D9%8A_%D8%A7%D9%84%D8%B1%D9%8A%D8%A7%D8%B6\",\n",
      "    \"tweet_volume\": 19839\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#DiaMundialSaludMental\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23DiaMundialSaludMental\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23DiaMundialSaludMental\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#DurbanStorm\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23DurbanStorm\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23DurbanStorm\",\n",
      "    \"tweet_volume\": 17761\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#DNA9thWin\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23DNA9thWin\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23DNA9thWin\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#AdaLovelaceDay\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23AdaLovelaceDay\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23AdaLovelaceDay\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#\\u0632\\u062f_\\u0631\\u0635\\u064a\\u062f\\u06438\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23%D8%B2%D8%AF_%D8%B1%D8%B5%D9%8A%D8%AF%D9%838\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23%D8%B2%D8%AF_%D8%B1%D8%B5%D9%8A%D8%AF%D9%838\",\n",
      "    \"tweet_volume\": 25739\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#\\u03b5\\u03bd\\u03b1\\u03c2_\\u03b5\\u03be\\u03c9\\u03b3\\u03b7\\u03b9\\u03bd\\u03bf\\u03c2_\\u03bc\\u03bf\\u03c5_\\u03b5\\u03b9\\u03c0\\u03b5\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23%CE%B5%CE%BD%CE%B1%CF%82_%CE%B5%CE%BE%CF%89%CE%B3%CE%B7%CE%B9%CE%BD%CE%BF%CF%82_%CE%BC%CE%BF%CF%85_%CE%B5%CE%B9%CF%80%CE%B5\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23%CE%B5%CE%BD%CE%B1%CF%82_%CE%B5%CE%BE%CF%89%CE%B3%CE%B7%CE%B9%CE%BD%CE%BF%CF%82_%CE%BC%CE%BF%CF%85_%CE%B5%CE%B9%CF%80%CE%B5\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#10EkimKatliam\\u0131n\\u0131Unutmad\\u0131k\",\n",
      "    \"url\": \"http://twitter.com/search?q=%2310EkimKatliam%C4%B1n%C4%B1Unutmad%C4%B1k\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%2310EkimKatliam%C4%B1n%C4%B1Unutmad%C4%B1k\",\n",
      "    \"tweet_volume\": 41175\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#SurvivorAU\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23SurvivorAU\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23SurvivorAU\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#\\u0627\\u0644\\u064a\\u0648\\u0645_\\u0627\\u0644\\u0639\\u0627\\u0644\\u0645\\u064a_\\u0644\\u0644\\u0635\\u062d\\u0647_\\u0627\\u0644\\u0646\\u0641\\u0633\\u064a\\u0647\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23%D8%A7%D9%84%D9%8A%D9%88%D9%85_%D8%A7%D9%84%D8%B9%D8%A7%D9%84%D9%85%D9%8A_%D9%84%D9%84%D8%B5%D8%AD%D9%87_%D8%A7%D9%84%D9%86%D9%81%D8%B3%D9%8A%D9%87\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23%D8%A7%D9%84%D9%8A%D9%88%D9%85_%D8%A7%D9%84%D8%B9%D8%A7%D9%84%D9%85%D9%8A_%D9%84%D9%84%D8%B5%D8%AD%D9%87_%D8%A7%D9%84%D9%86%D9%81%D8%B3%D9%8A%D9%87\",\n",
      "    \"tweet_volume\": 12706\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#WorldPorridgeDay\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23WorldPorridgeDay\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23WorldPorridgeDay\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#NUESTW_WHEREYOUAT\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23NUESTW_WHEREYOUAT\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23NUESTW_WHEREYOUAT\",\n",
      "    \"tweet_volume\": 200204\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#BedelliAskerlikGeliyor\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23BedelliAskerlikGeliyor\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23BedelliAskerlikGeliyor\",\n",
      "    \"tweet_volume\": 24948\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#NiallMondadoriDuomo\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23NiallMondadoriDuomo\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23NiallMondadoriDuomo\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#fiducia\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23fiducia\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23fiducia\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#SchoolLunchIn4Words\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23SchoolLunchIn4Words\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23SchoolLunchIn4Words\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#TuesdayThoughts\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23TuesdayThoughts\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23TuesdayThoughts\",\n",
      "    \"tweet_volume\": 19735\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#HUBFORUM\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23HUBFORUM\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23HUBFORUM\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#Welthundetag\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23Welthundetag\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23Welthundetag\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#\\u0647\\u0634\\u062a\\u0627\\u0642\\u0643_\\u0645\\u0639\\u0646\\u0627_\\u062a\\u0631\\u0646\\u062f_\\u0660\\u0665\\u0660\\u0667\\u0666\\u0666\\u0661\\u0664\\u0660\\u0669\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23%D9%87%D8%B4%D8%AA%D8%A7%D9%82%D9%83_%D9%85%D8%B9%D9%86%D8%A7_%D8%AA%D8%B1%D9%86%D8%AF_%D9%A0%D9%A5%D9%A0%D9%A7%D9%A6%D9%A6%D9%A1%D9%A4%D9%A0%D9%A9\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23%D9%87%D8%B4%D8%AA%D8%A7%D9%82%D9%83_%D9%85%D8%B9%D9%86%D8%A7_%D8%AA%D8%B1%D9%86%D8%AF_%D9%A0%D9%A5%D9%A0%D9%A7%D9%A6%D9%A6%D9%A1%D9%A4%D9%A0%D9%A9\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#SBBMat8\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23SBBMat8\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23SBBMat8\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#ATodoONada\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23ATodoONada\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23ATodoONada\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#Monetiza17\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23Monetiza17\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23Monetiza17\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#TercaDetremuraSDV\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23TercaDetremuraSDV\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23TercaDetremuraSDV\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#EuQueriaPararDe\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23EuQueriaPararDe\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23EuQueriaPararDe\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#KeepGoing\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23KeepGoing\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23KeepGoing\",\n",
      "    \"tweet_volume\": 41466\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#DvdD17\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23DvdD17\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23DvdD17\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#WildflowerKarma\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23WildflowerKarma\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23WildflowerKarma\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#charitytuesday\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23charitytuesday\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23charitytuesday\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#Budget18\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23Budget18\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23Budget18\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#October11SevenSundays\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23October11SevenSundays\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23October11SevenSundays\",\n",
      "    \"tweet_volume\": 65697\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#\\u0645\\u063a\\u0631\\u062f_\\u064a\\u0642\\u0630\\u0641_\\u0627\\u0644\\u0633\\u0639\\u0648\\u062f\\u064a\\u0627\\u062a\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23%D9%85%D8%BA%D8%B1%D8%AF_%D9%8A%D9%82%D8%B0%D9%81_%D8%A7%D9%84%D8%B3%D8%B9%D9%88%D8%AF%D9%8A%D8%A7%D8%AA\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23%D9%85%D8%BA%D8%B1%D8%AF_%D9%8A%D9%82%D8%B0%D9%81_%D8%A7%D9%84%D8%B3%D8%B9%D9%88%D8%AF%D9%8A%D8%A7%D8%AA\",\n",
      "    \"tweet_volume\": 64806\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#TekS\\u00f6z\\u00fcm\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23TekS%C3%B6z%C3%BCm\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23TekS%C3%B6z%C3%BCm\",\n",
      "    \"tweet_volume\": 10288\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#10ottobre\",\n",
      "    \"url\": \"http://twitter.com/search?q=%2310ottobre\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%2310ottobre\",\n",
      "    \"tweet_volume\": null\n",
      "   }\n",
      "  ],\n",
      "  \"as_of\": \"2017-10-10T12:02:27Z\",\n",
      "  \"created_at\": \"2017-10-10T11:54:19Z\",\n",
      "  \"locations\": [\n",
      "   {\n",
      "    \"name\": \"Worldwide\",\n",
      "    \"woeid\": 1\n",
      "   }\n",
      "  ]\n",
      " }\n",
      "]\n",
      "[\n",
      " {\n",
      "  \"trends\": [\n",
      "   {\n",
      "    \"name\": \"#WorldMentalHealthDay\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23WorldMentalHealthDay\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23WorldMentalHealthDay\",\n",
      "    \"tweet_volume\": 159905\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#SchoolLunchIn4Words\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23SchoolLunchIn4Words\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23SchoolLunchIn4Words\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#TuesdayThoughts\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23TuesdayThoughts\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23TuesdayThoughts\",\n",
      "    \"tweet_volume\": 20067\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"Tim Cahill\",\n",
      "    \"url\": \"http://twitter.com/search?q=%22Tim+Cahill%22\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%22Tim+Cahill%22\",\n",
      "    \"tweet_volume\": 11958\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"Deadly California\",\n",
      "    \"url\": \"http://twitter.com/search?q=%22Deadly+California%22\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%22Deadly+California%22\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"Virginia Is for Haters\",\n",
      "    \"url\": \"http://twitter.com/search?q=%22Virginia+Is+for+Haters%22\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%22Virginia+Is+for+Haters%22\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#kiss108jingleball\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23kiss108jingleball\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23kiss108jingleball\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#MorningJoe\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23MorningJoe\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23MorningJoe\",\n",
      "    \"tweet_volume\": 12260\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"Officer Louis Remigio\",\n",
      "    \"url\": \"http://twitter.com/search?q=%22Officer+Louis+Remigio%22\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%22Officer+Louis+Remigio%22\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"Fridtjof Nansen\",\n",
      "    \"url\": \"http://twitter.com/search?q=%22Fridtjof+Nansen%22\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%22Fridtjof+Nansen%22\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"Eliot\",\n",
      "    \"url\": \"http://twitter.com/search?q=Eliot\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"Eliot\",\n",
      "    \"tweet_volume\": 14348\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"Shirogane\",\n",
      "    \"url\": \"http://twitter.com/search?q=Shirogane\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"Shirogane\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"Iron Banner\",\n",
      "    \"url\": \"http://twitter.com/search?q=%22Iron+Banner%22\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%22Iron+Banner%22\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"SCHOOL DELAYS\",\n",
      "    \"url\": \"http://twitter.com/search?q=%22SCHOOL+DELAYS%22\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%22SCHOOL+DELAYS%22\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"Hollis Daniels\",\n",
      "    \"url\": \"http://twitter.com/search?q=%22Hollis+Daniels%22\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%22Hollis+Daniels%22\",\n",
      "    \"tweet_volume\": 10662\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"Mike Ditka\",\n",
      "    \"url\": \"http://twitter.com/search?q=%22Mike+Ditka%22\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%22Mike+Ditka%22\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"I-95 NB\",\n",
      "    \"url\": \"http://twitter.com/search?q=%22I-95+NB%22\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%22I-95+NB%22\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"Thelonious Monk\",\n",
      "    \"url\": \"http://twitter.com/search?q=%22Thelonious+Monk%22\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%22Thelonious+Monk%22\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"ESPN's Jemele Hill\",\n",
      "    \"url\": \"http://twitter.com/search?q=%22ESPN%27s+Jemele+Hill%22\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%22ESPN%27s+Jemele+Hill%22\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"George Clooney\",\n",
      "    \"url\": \"http://twitter.com/search?q=%22George+Clooney%22\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%22George+Clooney%22\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"Magnitude 6.3\",\n",
      "    \"url\": \"http://twitter.com/search?q=%22Magnitude+6.3%22\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%22Magnitude+6.3%22\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"Dense Fog Advisory\",\n",
      "    \"url\": \"http://twitter.com/search?q=%22Dense+Fog+Advisory%22\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%22Dense+Fog+Advisory%22\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"Kobe Steel\",\n",
      "    \"url\": \"http://twitter.com/search?q=%22Kobe+Steel%22\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%22Kobe+Steel%22\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"Indianapolis Colts\",\n",
      "    \"url\": \"http://twitter.com/search?q=%22Indianapolis+Colts%22\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%22Indianapolis+Colts%22\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"He Should Resign Immediately\",\n",
      "    \"url\": \"http://twitter.com/search?q=%22He+Should+Resign+Immediately%22\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%22He+Should+Resign+Immediately%22\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"Turtles All The Way Down\",\n",
      "    \"url\": \"http://twitter.com/search?q=%22Turtles+All+The+Way+Down%22\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%22Turtles+All+The+Way+Down%22\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#TravelTuesday\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23TravelTuesday\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23TravelTuesday\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#bfc530\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23bfc530\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23bfc530\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#WhatExesAreGoodFor\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23WhatExesAreGoodFor\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23WhatExesAreGoodFor\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#TheMarkets17\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23TheMarkets17\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23TheMarkets17\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#MysteryOREO\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23MysteryOREO\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23MysteryOREO\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#NLCS\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23NLCS\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23NLCS\",\n",
      "    \"tweet_volume\": 20858\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#n4tm\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23n4tm\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23n4tm\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#TISL\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23TISL\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23TISL\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#AdaLovelaceDay\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23AdaLovelaceDay\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23AdaLovelaceDay\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#nxStep\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23nxStep\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23nxStep\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#GPC2020\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23GPC2020\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23GPC2020\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#Shoptalkeurope\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23Shoptalkeurope\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23Shoptalkeurope\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#FIPPCongress\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23FIPPCongress\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23FIPPCongress\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#Daybreak\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23Daybreak\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23Daybreak\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#STMFrankfurt\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23STMFrankfurt\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23STMFrankfurt\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#GMRVA\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23GMRVA\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23GMRVA\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#WhatILearnedToday\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23WhatILearnedToday\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23WhatILearnedToday\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#BooksThatAreTasty\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23BooksThatAreTasty\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23BooksThatAreTasty\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#LendItEurope\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23LendItEurope\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23LendItEurope\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#liberiadecides\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23liberiadecides\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23liberiadecides\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#TacoTuesday\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23TacoTuesday\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23TacoTuesday\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#TJMS\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23TJMS\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23TJMS\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#NowForum\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23NowForum\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23NowForum\",\n",
      "    \"tweet_volume\": null\n",
      "   },\n",
      "   {\n",
      "    \"name\": \"#IQTday\",\n",
      "    \"url\": \"http://twitter.com/search?q=%23IQTday\",\n",
      "    \"promoted_content\": null,\n",
      "    \"query\": \"%23IQTday\",\n",
      "    \"tweet_volume\": null\n",
      "   }\n",
      "  ],\n",
      "  \"as_of\": \"2017-10-10T12:02:28Z\",\n",
      "  \"created_at\": \"2017-10-10T11:59:11Z\",\n",
      "  \"locations\": [\n",
      "   {\n",
      "    \"name\": \"United States\",\n",
      "    \"woeid\": 23424977\n",
      "   }\n",
      "  ]\n",
      " }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(world_trends, indent=1))\n",
    "print\n",
    "print(json.dumps(us_trends, indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An abbreviated sample response from the Trends API produced with\n",
    "      <code class=\"literal\">json.dumps</code> would look like the\n",
    "      following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>[\n",
    " {\n",
    "  \"created\\_at\": \"2013-03-27T11:50:40Z\", \n",
    "  \"trends\": [\n",
    "   {\n",
    "    \"url\": \"http://twitter.com/search?q=%23MentionSomeoneImportantForYou\", \n",
    "    \"query\": \"%23MentionSomeoneImportantForYou\", \n",
    "    \"name\": \"\\#MentionSomeoneImportantForYou\", \n",
    "    \"promoted\\_content\": null, \n",
    "    \"events\": null\n",
    "   },\n",
    "   ...\n",
    "  ]\n",
    " }\n",
    "]</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it's easy enough to skim the two sets of trends and look\n",
    "      for commonality, let's use Python's <a class=\"ulink\" href=\"http://bit.ly/1a1l2Sw\" target=\"\\_top\"><code class=\"literal\">set</code></a> data\n",
    "      structure to automatically compute this for us, because that's exactly\n",
    "      the kind of thing that sets lend themselves to doing. In this instance,\n",
    "      a <span class=\"emphasis\"><em>set</em></span> refers to the mathematical notion of a data\n",
    "      structure that stores an unordered collection of unique items and can be\n",
    "      computed upon with other sets of items and setwise operations. For\n",
    "      example, a setwise intersection computes common items between sets, a\n",
    "      setwise union combines all of the items from sets, and the setwise\n",
    "      difference among sets acts sort of like a subtraction operation in which\n",
    "      items from one set are removed from another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example&#160;1.4, &#8220;Computing the intersection of two sets of trends&#8221; demonstrates how to use a\n",
    "      Python <a class=\"ulink\" href=\"http://bit.ly/1a1l1hy\" target=\"\\_top\">list\n",
    "      comprehension</a> to parse out the names of the trending topics from\n",
    "      the results that were previously queried, cast those lists to sets, and\n",
    "      compute the setwise intersection to reveal the common items between\n",
    "      them. Keep in mind that there may or may not be significant overlap\n",
    "      between any given sets of trends, all depending on what's actually\n",
    "      happening when you query for the trends. In other words, the results of\n",
    "      your analysis will be entirely dependent upon your query and the data\n",
    "      that is returned from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote><div><strong>Note:</strong></div><p>Recall that Appendix&#160;C, <em>Python and IPython Notebook Tips &amp; Tricks</em> provides a reference for\n",
    "        some common Python idioms like list comprehensions that you may find\n",
    "        useful to review.</p></blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1.4. Computing the intersection of two sets of trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'#WorldMentalHealthDay', '#AdaLovelaceDay', '#TuesdayThoughts', '#SchoolLunchIn4Words'}\n"
     ]
    }
   ],
   "source": [
    "world_trends_set = set([trend['name'] \n",
    "                        for trend in world_trends[0]['trends']])\n",
    "\n",
    "us_trends_set = set([trend['name'] \n",
    "                     for trend in us_trends[0]['trends']]) \n",
    "\n",
    "common_trends = world_trends_set.intersection(us_trends_set)\n",
    "\n",
    "print(common_trends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote><div><strong>Note:</strong></div><p>You should complete Example&#160;1.4, &#8220;Computing the intersection of two sets of trends&#8221;\n",
    "        before moving on in this chapter to ensure that you are able to access\n",
    "        and analyze Twitter data. Can you explain what, if any, correlation\n",
    "        exists between trends in your country and the rest of the\n",
    "        world?</p></blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote><div><strong>Sidebar Discussion:</strong></div><div class=\"titlepage\">\n",
    "              <div>\n",
    "                <div>\n",
    "                  <div class=\"sidebar-title\">Set Theory, Intuition, and Countable Infinity</div>\n",
    "                </div>\n",
    "              </div>\n",
    "            </div>\n",
    "            <p>Computing setwise operations may seem a rather primitive form of\n",
    "        analysis, but the ramifications of set theory for general mathematics\n",
    "        are considerably more profound since it provides the foundation for\n",
    "        many mathematical principles.</p>\n",
    "            <p>Georg Cantor is generally credited with formalizing the mathematics\n",
    "        behind set theory, and his paper &#8220;On a Characteristic Property of All\n",
    "        Real Algebraic Numbers&#8221; (1874) formalized set theory as part of his\n",
    "        work on answering questions related to the concept of infinity. To\n",
    "        understand how it worked, consider the following question: is the set\n",
    "        of positive integers larger in cardinality than the set of both\n",
    "        positive and negative integers?</p>\n",
    "            <p>Although common intuition may be that there are twice as many\n",
    "        positive and negative integers than positive integers alone, Cantor&#8217;s\n",
    "        work showed that the cardinalities of the sets are actually equal!\n",
    "        Mathematically, he showed that you can map both sets of numbers such\n",
    "        that they form a sequence with a definite starting point that extends\n",
    "        forever in <span class=\"emphasis\"><em>one</em></span> direction like this: <span class=\"emphasis\"><em>{1,\n",
    "        &#8211;1, 2, &#8211;2, 3, &#8211;3, ...}</em></span>.</p>\n",
    "            <p>Because the numbers can be clearly enumerated but there is never an ending\n",
    "        point, the cardinalities of the sets are said to be\n",
    "        <span class=\"emphasis\"><em>countably infinite</em></span>. In other words, there is a\n",
    "        definite sequence that could be followed deterministically if you\n",
    "        simply had enough time to count them.</p></blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the common items between the sets of trending topics turns out\n",
    "      to be the hashtag \\#MentionSomeoneImportantForYou, so let's use it as the\n",
    "      basis of a search query to fetch some tweets for further analysis. Example&#160;1.5, &#8220;Collecting search results&#8221; illustrates how to exercise the <a class=\"ulink\" href=\"http://bit.ly/1a1l398\" target=\"\\_top\"><code class=\"literal\">GET search/tweets</code> resource</a> for a particular query of\n",
    "      interest, including the ability to use a special field that's included\n",
    "      in the metadata for the search results to easily make additional\n",
    "      requests for more search results. Coverage of Twitter's <a class=\"ulink\" href=\"http://bit.ly/1a1l1ya\" target=\"\\_top\">Streaming API</a> resources is out of\n",
    "      scope for this chapter but is introduced in &#8220;Sampling the Twitter Firehose with the <span class=\"keep-together\">Streaming API</span>&#8221; (Example&#160;9.8, &#8220;Sampling the Twitter firehose with the Streaming API&#8221;)\n",
    "      and may be more appropriate for many situations in which you want to\n",
    "      maintain a constantly updated view of tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote><div><strong>Note:</strong></div><p>The use of <code class=\"literal\">\\*args</code> and <code class=\"literal\">\\*\\*kwargs</code> as illustrated in Example&#160;1.5, &#8220;Collecting search results&#8221; as parameters to a function is a\n",
    "        Python idiom for expressing arbitrary arguments and keyword arguments,\n",
    "        respectively. See Appendix&#160;C, <em>Python and IPython Notebook Tips &amp; Tricks</em> for a brief overview of this\n",
    "        idiom.</p></blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1.5. Collecting search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of statuses 100\n",
      "Length of statuses 200\n",
      "Length of statuses 269\n",
      "{\n",
      " \"created_at\": \"Tue Oct 10 12:01:15 +0000 2017\",\n",
      " \"id\": 917721686824366080,\n",
      " \"id_str\": \"917721686824366080\",\n",
      " \"text\": \"RT @DeliciouslyP: I never knew how many #glutenfree #pizza crust options there really are!  It's fantastic! https://t.co/ojuoKCEthE https:/\\u2026\",\n",
      " \"truncated\": false,\n",
      " \"entities\": {\n",
      "  \"hashtags\": [\n",
      "   {\n",
      "    \"text\": \"glutenfree\",\n",
      "    \"indices\": [\n",
      "     40,\n",
      "     51\n",
      "    ]\n",
      "   },\n",
      "   {\n",
      "    \"text\": \"pizza\",\n",
      "    \"indices\": [\n",
      "     52,\n",
      "     58\n",
      "    ]\n",
      "   }\n",
      "  ],\n",
      "  \"symbols\": [],\n",
      "  \"user_mentions\": [\n",
      "   {\n",
      "    \"screen_name\": \"DeliciouslyP\",\n",
      "    \"name\": \"DeliciouslyPlated\",\n",
      "    \"id\": 797867441502191616,\n",
      "    \"id_str\": \"797867441502191616\",\n",
      "    \"indices\": [\n",
      "     3,\n",
      "     16\n",
      "    ]\n",
      "   }\n",
      "  ],\n",
      "  \"urls\": [\n",
      "   {\n",
      "    \"url\": \"https://t.co/ojuoKCEthE\",\n",
      "    \"expanded_url\": \"https://buff.ly/2glPWAz\",\n",
      "    \"display_url\": \"buff.ly/2glPWAz\",\n",
      "    \"indices\": [\n",
      "     108,\n",
      "     131\n",
      "    ]\n",
      "   }\n",
      "  ]\n",
      " },\n",
      " \"metadata\": {\n",
      "  \"iso_language_code\": \"en\",\n",
      "  \"result_type\": \"recent\"\n",
      " },\n",
      " \"source\": \"<a href=\\\"http://twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web Client</a>\",\n",
      " \"in_reply_to_status_id\": null,\n",
      " \"in_reply_to_status_id_str\": null,\n",
      " \"in_reply_to_user_id\": null,\n",
      " \"in_reply_to_user_id_str\": null,\n",
      " \"in_reply_to_screen_name\": null,\n",
      " \"user\": {\n",
      "  \"id\": 235205137,\n",
      "  \"id_str\": \"235205137\",\n",
      "  \"name\": \"Life in a Break Down\",\n",
      "  \"screen_name\": \"Life_BreakDown\",\n",
      "  \"location\": \"Lichfield, England\",\n",
      "  \"description\": \"UK Based #Lifestyle #Blogger | Impossibly Unique | Also found at @ukbloggers1 #ukbloggers\",\n",
      "  \"url\": \"https://t.co/IusKgD27Mc\",\n",
      "  \"entities\": {\n",
      "   \"url\": {\n",
      "    \"urls\": [\n",
      "     {\n",
      "      \"url\": \"https://t.co/IusKgD27Mc\",\n",
      "      \"expanded_url\": \"http://www.lifeinabreakdown.com\",\n",
      "      \"display_url\": \"lifeinabreakdown.com\",\n",
      "      \"indices\": [\n",
      "       0,\n",
      "       23\n",
      "      ]\n",
      "     }\n",
      "    ]\n",
      "   },\n",
      "   \"description\": {\n",
      "    \"urls\": []\n",
      "   }\n",
      "  },\n",
      "  \"protected\": false,\n",
      "  \"followers_count\": 23122,\n",
      "  \"friends_count\": 4023,\n",
      "  \"listed_count\": 487,\n",
      "  \"created_at\": \"Fri Jan 07 16:27:51 +0000 2011\",\n",
      "  \"favourites_count\": 10870,\n",
      "  \"utc_offset\": 3600,\n",
      "  \"time_zone\": \"London\",\n",
      "  \"geo_enabled\": false,\n",
      "  \"verified\": false,\n",
      "  \"statuses_count\": 51638,\n",
      "  \"lang\": \"en\",\n",
      "  \"contributors_enabled\": false,\n",
      "  \"is_translator\": false,\n",
      "  \"is_translation_enabled\": false,\n",
      "  \"profile_background_color\": \"674D58\",\n",
      "  \"profile_background_image_url\": \"http://pbs.twimg.com/profile_background_images/767458549/6f44cbfa52100049382d9049aaeaea6f.png\",\n",
      "  \"profile_background_image_url_https\": \"https://pbs.twimg.com/profile_background_images/767458549/6f44cbfa52100049382d9049aaeaea6f.png\",\n",
      "  \"profile_background_tile\": true,\n",
      "  \"profile_image_url\": \"http://pbs.twimg.com/profile_images/802298368156467201/4VFt6xA5_normal.jpg\",\n",
      "  \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/802298368156467201/4VFt6xA5_normal.jpg\",\n",
      "  \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/235205137/1431701755\",\n",
      "  \"profile_link_color\": \"5BCDCF\",\n",
      "  \"profile_sidebar_border_color\": \"BFDFEE\",\n",
      "  \"profile_sidebar_fill_color\": \"D3CFCC\",\n",
      "  \"profile_text_color\": \"C76469\",\n",
      "  \"profile_use_background_image\": true,\n",
      "  \"has_extended_profile\": true,\n",
      "  \"default_profile\": false,\n",
      "  \"default_profile_image\": false,\n",
      "  \"following\": false,\n",
      "  \"follow_request_sent\": false,\n",
      "  \"notifications\": false,\n",
      "  \"translator_type\": \"none\"\n",
      " },\n",
      " \"geo\": null,\n",
      " \"coordinates\": null,\n",
      " \"place\": null,\n",
      " \"contributors\": null,\n",
      " \"retweeted_status\": {\n",
      "  \"created_at\": \"Mon Oct 09 10:41:58 +0000 2017\",\n",
      "  \"id\": 917339347418075136,\n",
      "  \"id_str\": \"917339347418075136\",\n",
      "  \"text\": \"I never knew how many #glutenfree #pizza crust options there really are!  It's fantastic! https://t.co/ojuoKCEthE https://t.co/wuQRNCw0Za\",\n",
      "  \"truncated\": false,\n",
      "  \"entities\": {\n",
      "   \"hashtags\": [\n",
      "    {\n",
      "     \"text\": \"glutenfree\",\n",
      "     \"indices\": [\n",
      "      22,\n",
      "      33\n",
      "     ]\n",
      "    },\n",
      "    {\n",
      "     \"text\": \"pizza\",\n",
      "     \"indices\": [\n",
      "      34,\n",
      "      40\n",
      "     ]\n",
      "    }\n",
      "   ],\n",
      "   \"symbols\": [],\n",
      "   \"user_mentions\": [],\n",
      "   \"urls\": [\n",
      "    {\n",
      "     \"url\": \"https://t.co/ojuoKCEthE\",\n",
      "     \"expanded_url\": \"https://buff.ly/2glPWAz\",\n",
      "     \"display_url\": \"buff.ly/2glPWAz\",\n",
      "     \"indices\": [\n",
      "      90,\n",
      "      113\n",
      "     ]\n",
      "    }\n",
      "   ],\n",
      "   \"media\": [\n",
      "    {\n",
      "     \"id\": 917339344486010880,\n",
      "     \"id_str\": \"917339344486010880\",\n",
      "     \"indices\": [\n",
      "      114,\n",
      "      137\n",
      "     ],\n",
      "     \"media_url\": \"http://pbs.twimg.com/media/DLsLRgaUEAA0F7U.jpg\",\n",
      "     \"media_url_https\": \"https://pbs.twimg.com/media/DLsLRgaUEAA0F7U.jpg\",\n",
      "     \"url\": \"https://t.co/wuQRNCw0Za\",\n",
      "     \"display_url\": \"pic.twitter.com/wuQRNCw0Za\",\n",
      "     \"expanded_url\": \"https://twitter.com/DeliciouslyP/status/917339347418075136/photo/1\",\n",
      "     \"type\": \"photo\",\n",
      "     \"sizes\": {\n",
      "      \"large\": {\n",
      "       \"w\": 735,\n",
      "       \"h\": 1102,\n",
      "       \"resize\": \"fit\"\n",
      "      },\n",
      "      \"thumb\": {\n",
      "       \"w\": 150,\n",
      "       \"h\": 150,\n",
      "       \"resize\": \"crop\"\n",
      "      },\n",
      "      \"medium\": {\n",
      "       \"w\": 735,\n",
      "       \"h\": 1102,\n",
      "       \"resize\": \"fit\"\n",
      "      },\n",
      "      \"small\": {\n",
      "       \"w\": 454,\n",
      "       \"h\": 680,\n",
      "       \"resize\": \"fit\"\n",
      "      }\n",
      "     }\n",
      "    }\n",
      "   ]\n",
      "  },\n",
      "  \"extended_entities\": {\n",
      "   \"media\": [\n",
      "    {\n",
      "     \"id\": 917339344486010880,\n",
      "     \"id_str\": \"917339344486010880\",\n",
      "     \"indices\": [\n",
      "      114,\n",
      "      137\n",
      "     ],\n",
      "     \"media_url\": \"http://pbs.twimg.com/media/DLsLRgaUEAA0F7U.jpg\",\n",
      "     \"media_url_https\": \"https://pbs.twimg.com/media/DLsLRgaUEAA0F7U.jpg\",\n",
      "     \"url\": \"https://t.co/wuQRNCw0Za\",\n",
      "     \"display_url\": \"pic.twitter.com/wuQRNCw0Za\",\n",
      "     \"expanded_url\": \"https://twitter.com/DeliciouslyP/status/917339347418075136/photo/1\",\n",
      "     \"type\": \"photo\",\n",
      "     \"sizes\": {\n",
      "      \"large\": {\n",
      "       \"w\": 735,\n",
      "       \"h\": 1102,\n",
      "       \"resize\": \"fit\"\n",
      "      },\n",
      "      \"thumb\": {\n",
      "       \"w\": 150,\n",
      "       \"h\": 150,\n",
      "       \"resize\": \"crop\"\n",
      "      },\n",
      "      \"medium\": {\n",
      "       \"w\": 735,\n",
      "       \"h\": 1102,\n",
      "       \"resize\": \"fit\"\n",
      "      },\n",
      "      \"small\": {\n",
      "       \"w\": 454,\n",
      "       \"h\": 680,\n",
      "       \"resize\": \"fit\"\n",
      "      }\n",
      "     }\n",
      "    }\n",
      "   ]\n",
      "  },\n",
      "  \"metadata\": {\n",
      "   \"iso_language_code\": \"en\",\n",
      "   \"result_type\": \"recent\"\n",
      "  },\n",
      "  \"source\": \"<a href=\\\"http://bufferapp.com\\\" rel=\\\"nofollow\\\">Buffer</a>\",\n",
      "  \"in_reply_to_status_id\": null,\n",
      "  \"in_reply_to_status_id_str\": null,\n",
      "  \"in_reply_to_user_id\": null,\n",
      "  \"in_reply_to_user_id_str\": null,\n",
      "  \"in_reply_to_screen_name\": null,\n",
      "  \"user\": {\n",
      "   \"id\": 797867441502191616,\n",
      "   \"id_str\": \"797867441502191616\",\n",
      "   \"name\": \"DeliciouslyPlated\",\n",
      "   \"screen_name\": \"DeliciouslyP\",\n",
      "   \"location\": \"Raleigh, NC\",\n",
      "   \"description\": \"Wife, Mother, Food Blogger, Photographer\",\n",
      "   \"url\": \"https://t.co/9zKwUN7XfW\",\n",
      "   \"entities\": {\n",
      "    \"url\": {\n",
      "     \"urls\": [\n",
      "      {\n",
      "       \"url\": \"https://t.co/9zKwUN7XfW\",\n",
      "       \"expanded_url\": \"https://www.deliciouslyplated.com\",\n",
      "       \"display_url\": \"deliciouslyplated.com\",\n",
      "       \"indices\": [\n",
      "        0,\n",
      "        23\n",
      "       ]\n",
      "      }\n",
      "     ]\n",
      "    },\n",
      "    \"description\": {\n",
      "     \"urls\": []\n",
      "    }\n",
      "   },\n",
      "   \"protected\": false,\n",
      "   \"followers_count\": 471,\n",
      "   \"friends_count\": 163,\n",
      "   \"listed_count\": 3,\n",
      "   \"created_at\": \"Sun Nov 13 18:23:16 +0000 2016\",\n",
      "   \"favourites_count\": 309,\n",
      "   \"utc_offset\": null,\n",
      "   \"time_zone\": null,\n",
      "   \"geo_enabled\": false,\n",
      "   \"verified\": false,\n",
      "   \"statuses_count\": 1777,\n",
      "   \"lang\": \"en\",\n",
      "   \"contributors_enabled\": false,\n",
      "   \"is_translator\": false,\n",
      "   \"is_translation_enabled\": false,\n",
      "   \"profile_background_color\": \"F5F8FA\",\n",
      "   \"profile_background_image_url\": null,\n",
      "   \"profile_background_image_url_https\": null,\n",
      "   \"profile_background_tile\": false,\n",
      "   \"profile_image_url\": \"http://pbs.twimg.com/profile_images/862741536836071425/KLyw-CcS_normal.jpg\",\n",
      "   \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/862741536836071425/KLyw-CcS_normal.jpg\",\n",
      "   \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/797867441502191616/1494528538\",\n",
      "   \"profile_link_color\": \"1DA1F2\",\n",
      "   \"profile_sidebar_border_color\": \"C0DEED\",\n",
      "   \"profile_sidebar_fill_color\": \"DDEEF6\",\n",
      "   \"profile_text_color\": \"333333\",\n",
      "   \"profile_use_background_image\": true,\n",
      "   \"has_extended_profile\": true,\n",
      "   \"default_profile\": true,\n",
      "   \"default_profile_image\": false,\n",
      "   \"following\": false,\n",
      "   \"follow_request_sent\": false,\n",
      "   \"notifications\": false,\n",
      "   \"translator_type\": \"none\"\n",
      "  },\n",
      "  \"geo\": null,\n",
      "  \"coordinates\": null,\n",
      "  \"place\": null,\n",
      "  \"contributors\": null,\n",
      "  \"is_quote_status\": false,\n",
      "  \"retweet_count\": 36,\n",
      "  \"favorite_count\": 17,\n",
      "  \"favorited\": false,\n",
      "  \"retweeted\": false,\n",
      "  \"possibly_sensitive\": false,\n",
      "  \"lang\": \"en\"\n",
      " },\n",
      " \"is_quote_status\": false,\n",
      " \"retweet_count\": 36,\n",
      " \"favorite_count\": 0,\n",
      " \"favorited\": false,\n",
      " \"retweeted\": false,\n",
      " \"possibly_sensitive\": false,\n",
      " \"lang\": \"en\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Import unquote to prevent url encoding errors in next_results\n",
    "from urllib.parse import unquote\n",
    "\n",
    "# XXX: Set this variable to a trending topic, \n",
    "# or anything else for that matter. The example query below\n",
    "# was a trending topic when this content was being developed\n",
    "# and is used throughout the remainder of this chapter.\n",
    "\n",
    "q = '#Pizza' \n",
    "\n",
    "count = 100\n",
    "\n",
    "# See https://dev.twitter.com/docs/api/1.1/get/search/tweets\n",
    "\n",
    "search_results = twitter_api.search.tweets(q=q, count=count)\n",
    "\n",
    "statuses = search_results['statuses']\n",
    "\n",
    "\n",
    "# Iterate through 5 more batches of results by following the cursor\n",
    "\n",
    "for _ in range(5):\n",
    "    print(\"Length of statuses\", len(statuses))\n",
    "    try:\n",
    "        next_results = search_results['search_metadata']['next_results']\n",
    "    except KeyError: # No more results when next_results doesn't exist\n",
    "        break\n",
    "        \n",
    "    # Create a dictionary from next_results, which has the following form:\n",
    "    # ?max_id=313519052523986943&q=NCAA&include_entities=1\n",
    "    kwargs = dict([kv.split('=') for kv in unquote(next_results[1:]).split(\"&\") ])    \n",
    "\n",
    "    \n",
    "    search_results = twitter_api.search.tweets(**kwargs)\n",
    "    statuses += search_results['statuses']\n",
    "\n",
    "# Show one sample search result by slicing the list...\n",
    "print(json.dumps(statuses[0], indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote><div><strong>Note:</strong></div><p>Although we're just passing in a hashtag to the Search API at\n",
    "        this point, it's well worth noting that it contains a number of <a class=\"ulink\" href=\"http://bit.ly/1a1l3pN\" target=\"\\_top\">powerful operators</a> that allow you\n",
    "        to filter queries according to the existence or nonexistence of\n",
    "        various keywords, originator of the tweet, location associated with\n",
    "        the tweet, etc.</p></blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In essence, all the code does is repeatedly make requests to the Search API.\n",
    "      One thing that might initially catch you off guard if you've worked with\n",
    "      other web APIs (including version 1 of Twitter's API) is that there's no\n",
    "      explicit concept of <span class=\"emphasis\"><em>pagination</em></span> in the Search API\n",
    "      itself. Reviewing the API documentation reveals that this is a\n",
    "      intentional decision, and there are some <a class=\"ulink\" href=\"http://bit.ly/1a1l4K6\" target=\"\\_top\">good reasons</a> for taking a\n",
    "      <span class=\"emphasis\"><em>cursoring</em></span> approach instead, given the highly\n",
    "      dynamic state of Twitter resources. The best practices for cursoring\n",
    "      vary a bit throughout the Twitter developer platform, with the Search\n",
    "      API providing a slightly simpler way of navigating search results than\n",
    "      other resources such as timelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search results contain a special <code class=\"literal\">search\\_metadata</code> node that embeds a <code class=\"literal\">next\\_results</code> field with a query string that\n",
    "      provides the basis of a subsequent query. If we weren't using a library\n",
    "      like <code class=\"literal\">twitter</code> to make the HTTP\n",
    "      requests for us, this preconstructed query string would just be appended\n",
    "      to the Search API URL, and we'd update it with additional parameters for\n",
    "      handling OAuth. However, since we are not making our HTTP requests\n",
    "      directly, we must parse the query string into its constituent key/value\n",
    "      pairs and provide them as keyword arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python parlance, we are <span class=\"emphasis\"><em>unpacking</em></span> the\n",
    "      values in a dictionary into keyword arguments that the function\n",
    "      receives. In other words, the function call inside of the <code class=\"literal\">for</code> loop in <span class=\"keep-together\">Example&#160;1.5, &#8220;Collecting search results&#8221; ultimately invokes a function such as\n",
    "      <code class=\"literal\">twitter\\_api.search.tweets</code></span><code class=\"literal\">(q='%23MentionSomeoneImportantForYou',\n",
    "      include\\_entities=1, max\\_id=313519</code><span class=\"keep-together\"><code class=\"literal\">052523986943)</code> even though it appears in\n",
    "      the source code as <code class=\"literal\">twitter\\_api</code></span><code class=\"literal\">.search.tweets(\\*\\*kwargs)</code>, with <code class=\"literal\">kwargs</code> being a dictionary of key/value\n",
    "      pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote><div><strong>Note:</strong></div><p>The <code class=\"literal\">search\\_metadata</code> field\n",
    "        also contains a <code class=\"literal\">refresh\\_url</code> value\n",
    "        that can be used if you'd like to maintain and periodically update\n",
    "        your collection of results with new information that's become\n",
    "        available since the previous query.</p></blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next sample tweet shows the search results for a query for\n",
    "      \\#MentionSomeoneImportantForYou. Take a moment to peruse (all of) it. As\n",
    "      I mentioned earlier, there's a lot more to a tweet than meets the eye.\n",
    "      The particular tweet that follows is fairly representative and contains\n",
    "      in excess of 5 KB of total content when represented in uncompressed\n",
    "      JSON. That's more than 40 times the amount of data that makes up the 140\n",
    "      characters of text that's normally thought of as a tweet!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>[\n",
    " {\n",
    "  \"contributors\": null, \n",
    "  \"truncated\": false, \n",
    "  \"text\": \"RT @hassanmusician: \\#MentionSomeoneImportantForYou God.\", \n",
    "  \"in\\_reply\\_to\\_status\\_id\": null, \n",
    "  \"id\": 316948241264549888, \n",
    "  \"favorite\\_count\": 0, \n",
    "  \"source\": \"<a href=\\\"http://twitter.com/download/android\\\"...\", \n",
    "  \"retweeted\": false, \n",
    "  \"coordinates\": null, \n",
    "  \"entities\": {\n",
    "   \"user\\_mentions\": [\n",
    "    {\n",
    "     \"id\": 56259379, \n",
    "     \"indices\": [\n",
    "      3, \n",
    "      18\n",
    "     ], \n",
    "     \"id\\_str\": \"56259379\", \n",
    "     \"screen\\_name\": \"hassanmusician\", \n",
    "     \"name\": \"Download the NEW LP!\"\n",
    "    }\n",
    "   ], \n",
    "   \"hashtags\": [\n",
    "    {\n",
    "     \"indices\": [\n",
    "      20, \n",
    "      50\n",
    "     ], \n",
    "     \"text\": \"MentionSomeoneImportantForYou\"\n",
    "    }\n",
    "   ], \n",
    "   \"urls\": []\n",
    "  }, \n",
    "  \"in\\_reply\\_to\\_screen\\_name\": null, \n",
    "  \"in\\_reply\\_to\\_user\\_id\": null, \n",
    "  \"retweet\\_count\": 23, \n",
    "  \"id\\_str\": \"316948241264549888\", \n",
    "  \"favorited\": false, \n",
    "  \"retweeted\\_status\": {\n",
    "   \"contributors\": null, \n",
    "   \"truncated\": false, \n",
    "   \"text\": \"\\#MentionSomeoneImportantForYou God.\", \n",
    "   \"in\\_reply\\_to\\_status\\_id\": null, \n",
    "   \"id\": 316944833233186816, \n",
    "   \"favorite\\_count\": 0, \n",
    "   \"source\": \"web\", \n",
    "   \"retweeted\": false, \n",
    "   \"coordinates\": null, \n",
    "   \"entities\": {\n",
    "    \"user\\_mentions\": [], \n",
    "    \"hashtags\": [\n",
    "     {\n",
    "      \"indices\": [\n",
    "       0, \n",
    "       30\n",
    "      ], \n",
    "      \"text\": \"MentionSomeoneImportantForYou\"\n",
    "     }\n",
    "    ], \n",
    "    \"urls\": []\n",
    "   }, \n",
    "   \"in\\_reply\\_to\\_screen\\_name\": null, \n",
    "   \"in\\_reply\\_to\\_user\\_id\": null, \n",
    "   \"retweet\\_count\": 23, \n",
    "   \"id\\_str\": \"316944833233186816\", \n",
    "   \"favorited\": false, \n",
    "   \"user\": {\n",
    "    \"follow\\_request\\_sent\": null, \n",
    "    \"profile\\_use\\_background\\_image\": true, \n",
    "    \"default\\_profile\\_image\": false, \n",
    "    \"id\": 56259379, \n",
    "    \"verified\": false, \n",
    "    \"profile\\_text\\_color\": \"3C3940\", \n",
    "    \"profile\\_image\\_url\\_https\": \"https://si0.t...\", \n",
    "    \"profile\\_sidebar\\_fill\\_color\": \"95E8EC\", \n",
    "    \"entities\": {\n",
    "     \"url\": {\n",
    "      \"urls\": [\n",
    "       {\n",
    "        \"url\": \"http://t.co/yRX89YM4J0\", \n",
    "        \"indices\": [\n",
    "         0, \n",
    "         22\n",
    "        ], \n",
    "        \"expanded\\_url\": \"http://www.datpiff...\", \n",
    "        \"display\\_url\": \"datpiff.com/mixtapes-detai\\u2026\"\n",
    "       }\n",
    "      ]\n",
    "     }, \n",
    "     \"description\": {\n",
    "      \"urls\": []\n",
    "     }\n",
    "    }, \n",
    "    \"followers\\_count\": 105041, \n",
    "    \"profile\\_sidebar\\_border\\_color\": \"000000\", \n",
    "    \"id\\_str\": \"56259379\", \n",
    "    \"profile\\_background\\_color\": \"000000\", \n",
    "    \"listed\\_count\": 64, \n",
    "    \"profile\\_background\\_image\\_url\\_https\": \"https://si0.t...\", \n",
    "    \"utc\\_offset\": -18000, \n",
    "    \"statuses\\_count\": 16691, \n",
    "    \"description\": \"\\#TheseAreTheWordsISaid LP\", \n",
    "    \"friends\\_count\": 59615, \n",
    "    \"location\": \"\", \n",
    "    \"profile\\_link\\_color\": \"91785A\", \n",
    "    \"profile\\_image\\_url\": \"http://a0.twimg.com/...\", \n",
    "    \"following\": null, \n",
    "    \"geo\\_enabled\": true, \n",
    "    \"profile\\_banner\\_url\": \"https://si0.twimg.com/pr...\", \n",
    "    \"profile\\_background\\_image\\_url\": \"http://a0.twi...\", \n",
    "    \"screen\\_name\": \"hassanmusician\", \n",
    "    \"lang\": \"en\", \n",
    "    \"profile\\_background\\_tile\": false, \n",
    "    \"favourites\\_count\": 6142, \n",
    "    \"name\": \"Download the NEW LP!\", \n",
    "    \"notifications\": null, \n",
    "    \"url\": \"http://t.co/yRX89YM4J0\", \n",
    "    \"created\\_at\": \"Mon Jul 13 02:18:25 +0000 2009\", \n",
    "    \"contributors\\_enabled\": false, \n",
    "    \"time\\_zone\": \"Eastern Time (US & Canada)\", \n",
    "    \"protected\": false, \n",
    "    \"default\\_profile\": false, \n",
    "    \"is\\_translator\": false\n",
    "   }, \n",
    "   \"geo\": null, \n",
    "   \"in\\_reply\\_to\\_user\\_id\\_str\": null, \n",
    "   \"lang\": \"en\", \n",
    "   \"created\\_at\": \"Wed Mar 27 16:08:31 +0000 2013\", \n",
    "   \"in\\_reply\\_to\\_status\\_id\\_str\": null, \n",
    "   \"place\": null, \n",
    "   \"metadata\": {\n",
    "    \"iso\\_language\\_code\": \"en\", \n",
    "    \"result\\_type\": \"recent\"\n",
    "   }\n",
    "  }, \n",
    "  \"user\": {\n",
    "   \"follow\\_request\\_sent\": null, \n",
    "   \"profile\\_use\\_background\\_image\": true, \n",
    "   \"default\\_profile\\_image\": false, \n",
    "   \"id\": 549413966, \n",
    "   \"verified\": false, \n",
    "   \"profile\\_text\\_color\": \"3D1957\", \n",
    "   \"profile\\_image\\_url\\_https\": \"https://si0.twimg...\", \n",
    "   \"profile\\_sidebar\\_fill\\_color\": \"7AC3EE\", \n",
    "   \"entities\": {\n",
    "    \"description\": {\n",
    "     \"urls\": []\n",
    "    }\n",
    "   }, \n",
    "   \"followers\\_count\": 110, \n",
    "   \"profile\\_sidebar\\_border\\_color\": \"FFFFFF\", \n",
    "   \"id\\_str\": \"549413966\", \n",
    "   \"profile\\_background\\_color\": \"642D8B\", \n",
    "   \"listed\\_count\": 1, \n",
    "   \"profile\\_background\\_image\\_url\\_https\": \"https:...\", \n",
    "   \"utc\\_offset\": 0, \n",
    "   \"statuses\\_count\": 1294, \n",
    "   \"description\": \"i BELIEVE do you? I admire n adore @justinbieber \", \n",
    "   \"friends\\_count\": 346, \n",
    "   \"location\": \"All Around The World \", \n",
    "   \"profile\\_link\\_color\": \"FF0000\", \n",
    "   \"profile\\_image\\_url\": \"http://a0.twimg.com/pr...\", \n",
    "   \"following\": null, \n",
    "   \"geo\\_enabled\": true, \n",
    "   \"profile\\_banner\\_url\": \"https://si0.twimg.com/...\", \n",
    "   \"profile\\_background\\_image\\_url\": \"http://a0.tw...\", \n",
    "   \"screen\\_name\": \"LilSalima\", \n",
    "   \"lang\": \"en\", \n",
    "   \"profile\\_background\\_tile\": true, \n",
    "   \"favourites\\_count\": 229, \n",
    "   \"name\": \"KoKo :D\", \n",
    "   \"notifications\": null, \n",
    "   \"url\": null, \n",
    "   \"created\\_at\": \"Mon Apr 09 17:51:36 +0000 2012\", \n",
    "   \"contributors\\_enabled\": false, \n",
    "   \"time\\_zone\": \"London\", \n",
    "   \"protected\": false, \n",
    "   \"default\\_profile\": false, \n",
    "   \"is\\_translator\": false\n",
    "  }, \n",
    "  \"geo\": null, \n",
    "  \"in\\_reply\\_to\\_user\\_id\\_str\": null, \n",
    "  \"lang\": \"en\", \n",
    "  \"created\\_at\": \"Wed Mar 27 16:22:03 +0000 2013\", \n",
    "  \"in\\_reply\\_to\\_status\\_id\\_str\": null, \n",
    "  \"place\": null, \n",
    "  \"metadata\": {\n",
    "   \"iso\\_language\\_code\": \"en\", \n",
    "   \"result\\_type\": \"recent\"\n",
    "  }\n",
    " }, \n",
    " ...\n",
    "]</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweets are imbued with some of the richest metadata that you'll\n",
    "      find on the social web, and Chapter&#160;9, <em>Twitter Cookbook</em>\n",
    "      elaborates on some of the many possibilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the 140 Characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The online documentation is always the definitive source for Twitter\n",
    "    platform objects, and it's worthwhile to bookmark the <a class=\"ulink\" href=\"http://bit.ly/1a1l3WL\" target=\"\\_top\">Tweets</a> page, because it's one that\n",
    "    you'll refer to quite frequently as you get familiarized with the basic\n",
    "    anatomy of a tweet. No attempt is made here or elsewhere in the book to\n",
    "    regurgitate online documentation, but a few notes are of interest given\n",
    "    that you might still be a bit overwhelmed by the 5 KB of information that\n",
    "    a tweet comprises. For simplicity of nomenclature, let's assume that we've\n",
    "    extracted a single tweet from the search results and stored it in a\n",
    "    variable named <code class=\"literal\">t</code>. For example, <code class=\"literal\">t.keys()</code> returns the top-level fields for the\n",
    "    tweet and <code class=\"literal\">t['id']</code> accesses the\n",
    "    identifier of the tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote><div><strong>Note:</strong></div><p>If you're following along with the IPython Notebook for this\n",
    "        chapter, the exact tweet that's under scrutiny is stored in a variable\n",
    "        named <code class=\"literal\">t</code> so that you can\n",
    "        interactively access its fields and explore more easily. The current\n",
    "        discussion assumes the same nomenclature, so values should correspond\n",
    "        one-for-one.</p></blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul class=\"itemizedlist\">\n",
    "            <li class=\"listitem\">\n",
    "              <p>The human-readable text of a tweet is available through <code class=\"literal\">t['text']</code>:</p>\n",
    "              <div class=\"programlisting\">RT @hassanmusician: \\#MentionSomeoneImportantForYou God.</div>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>The entities in the text of a tweet are conveniently processed\n",
    "          for you and available through <code class=\"literal\">t['entities']</code>:</p>\n",
    "              <div class=\"programlisting\">{\n",
    " \"user\\_mentions\": [\n",
    "  {\n",
    "   \"indices\": [\n",
    "    3, \n",
    "    18\n",
    "   ], \n",
    "   \"screen\\_name\": \"hassanmusician\", \n",
    "   \"id\": 56259379, \n",
    "   \"name\": \"Download the NEW LP!\", \n",
    "   \"id\\_str\": \"56259379\"\n",
    "  }\n",
    " ], \n",
    " \"hashtags\": [\n",
    "  {\n",
    "   \"indices\": [\n",
    "    20, \n",
    "    50\n",
    "   ], \n",
    "   \"text\": \"MentionSomeoneImportantForYou\"\n",
    "  }\n",
    " ], \n",
    " \"urls\": []\n",
    "}</div>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>Clues as to the \"interestingness\" of a tweet are available through <code class=\"literal\">t['favorite\\_count']</code> and <code class=\"literal\">t['retweet\\_count']</code>, which return the\n",
    "          number of times it's been bookmarked or retweeted,\n",
    "          respectively.</p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>If a tweet has been retweeted, the <code class=\"literal\">t['retweeted\\_status']</code> field provides\n",
    "          significant detail about the original tweet itself and its author.\n",
    "          Keep in mind that sometimes the text of a tweet changes as it is\n",
    "          retweeted, as users add reactions or otherwise manipulate the\n",
    "          text.</p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>The <code class=\"literal\">t['retweeted']</code> field\n",
    "          denotes whether or not the authenticated user (via an\n",
    "          authorized application) has retweeted this particular tweet. Fields\n",
    "          that vary <span class=\"keep-together\">depending</span> upon the\n",
    "          point of view of the particular user are denoted in Twitter's\n",
    "          developer documentation as <span class=\"emphasis\"><em>perspectival</em></span>, which\n",
    "          means that their values will vary depending upon the perspective of\n",
    "          the user.</p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>Additionally, note that only original tweets are retweeted\n",
    "          from the standpoint of the API and information management. Thus, the\n",
    "          <code class=\"literal\">retweet\\_count</code> reflects the total\n",
    "          number of times that the original tweet has been retweeted and\n",
    "          should reflect the same value in both the original tweet and all\n",
    "          subsequent retweets. In other words, retweets aren't retweeted. It\n",
    "          may be a bit counterintuitive at first, but if you think you're\n",
    "          retweeting a retweet, you're actually just retweeting the original\n",
    "          tweet that you were exposed to through a proxy. See &#8220;Examining Patterns in Retweets&#8221; later in this chapter for a\n",
    "          more nuanced discussion about the difference between retweeting vs\n",
    "          quoting a tweet.</p>\n",
    "            </li>\n",
    "          </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should tinker around with the sample tweet and consult the\n",
    "    documentation to clarify any lingering questions you might have before\n",
    "    moving forward. A good working knowledge of a tweet's anatomy is critical\n",
    "    to effectively mining Twitter data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Tweet Entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's distill the entities and the text of the tweets into a convenient data\n",
    "      structure for further examination. Example&#160;1.6, &#8220;Extracting text, screen names, and hashtags from tweets&#8221;\n",
    "      extracts the text, screen names, and hashtags from the tweets that are\n",
    "      collected and introduces a Python idiom called a <span class=\"emphasis\"><em>double</em></span> (or\n",
    "      <span class=\"emphasis\"><em>nested</em></span>) <span class=\"emphasis\"><em>list comprehension</em></span>. If\n",
    "      you understand a (single) list comprehension, the code formatting should\n",
    "      illustrate the double list comprehension as simply a collection of\n",
    "      values that are derived from a nested loop as opposed to the results of\n",
    "      a single loop. List comprehensions are particularly powerful because\n",
    "      they usually yield substantial performance gains over nested lists and\n",
    "      provide an intuitive (once you&#8217;re familiar with them) yet terse\n",
    "      syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote><div><strong>Note:</strong></div><p>List comprehensions are used frequently throughout this book,\n",
    "          and it's worth consulting Appendix&#160;C, <em>Python and IPython Notebook Tips &amp; Tricks</em> or the <a class=\"ulink\" href=\"http://bit.ly/1a1l1hy\" target=\"\\_top\">official Python tutorial</a> for\n",
    "          more details if you'd like additional context.</p></blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1.6. Extracting text, screen names, and hashtags from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      " \"RT @DeliciouslyP: I never knew how many #glutenfree #pizza crust options there really are!  It's fantastic! https://t.co/ojuoKCEthE https:/\\u2026\",\n",
      " \"Thinking of having a Pizza? Call us @ 708-403-3335 20% OFF Thur-Sun 4 -8pm #pizza #italianvilllapizza #OrlandPark https://t.co/rC7LfF9tc8\",\n",
      " \"RT @LolaLoMCR: Retweet for your chance win complimentary pizza tonight for you and 3 friends!\\n\\nWinner announced at 5pm.\\n#pizza #competition\\u2026\",\n",
      " \"#Brighton #hove# portslade #Best #pizza #youtube via https://t.co/yPsX7pxCkU https://t.co/MOeUSz5Obt\",\n",
      " \"Feliz #martes a todos los amantes de la buena #pizza \\ud83c\\udf55 italiana \\ud83d\\ude0d hoy todas a 5\\u20ac. Tambi\\u00e9n #singluten \\ud83e\\udd17\\n\\n*Avisar al\\u2026 https://t.co/aWVsjGSATw\"\n",
      "]\n",
      "[\n",
      " \"DeliciouslyP\",\n",
      " \"LolaLoMCR\",\n",
      " \"MaverickBingley\",\n",
      " \"thedailymeal\",\n",
      " \"lalybarchi\"\n",
      "]\n",
      "[\n",
      " \"glutenfree\",\n",
      " \"pizza\",\n",
      " \"pizza\",\n",
      " \"italianvilllapizza\",\n",
      " \"OrlandPark\"\n",
      "]\n",
      "[\n",
      " \"RT\",\n",
      " \"@DeliciouslyP:\",\n",
      " \"I\",\n",
      " \"never\",\n",
      " \"knew\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "status_texts = [ status['text'] \n",
    "                 for status in statuses ]\n",
    "\n",
    "screen_names = [ user_mention['screen_name'] \n",
    "                 for status in statuses\n",
    "                     for user_mention in status['entities']['user_mentions'] ]\n",
    "\n",
    "hashtags = [ hashtag['text'] \n",
    "             for status in statuses\n",
    "                 for hashtag in status['entities']['hashtags'] ]\n",
    "\n",
    "# Compute a collection of all words from all tweets\n",
    "words = [ w \n",
    "          for t in status_texts \n",
    "              for w in t.split() ]\n",
    "\n",
    "# Explore the first 5 items for each...\n",
    "\n",
    "print(json.dumps(status_texts[0:5], indent=1))\n",
    "print(json.dumps(screen_names[0:5], indent=1))\n",
    "print(json.dumps(hashtags[0:5], indent=1))\n",
    "print(json.dumps(words[0:5], indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample output follows; it displays five status texts, screen\n",
    "      names, and hashtags to provide a feel for what's in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote><div><strong>Note:</strong></div><p>In Python, syntax in which square brackets appear after a list\n",
    "        or string value, such as <code class=\"literal\">status\\_texts[0:5]</code>, is indicative of\n",
    "        <span class=\"emphasis\"><em>slicing</em></span>, whereby you can easily extract items\n",
    "        from lists or substrings from strings. In this particular case,\n",
    "        <code class=\"literal\">[0:5]</code> indicates that you'd like the\n",
    "        first five items in the list <code class=\"literal\">status\\_texts</code> (corresponding to items at\n",
    "        indices 0 through 4). See Appendix&#160;C, <em>Python and IPython Notebook Tips &amp; Tricks</em> for a more extended\n",
    "        description of slicing in Python.</p></blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>[\n",
    " \"\\u201c@KathleenMariee\\_: \\#MentionSomeOneImportantForYou @AhhlicksCruise..., \n",
    " \"\\#MentionSomeoneImportantForYou My bf @Linkin\\_Sunrise.\", \n",
    " \"RT @hassanmusician: \\#MentionSomeoneImportantForYou God.\", \n",
    " \"\\#MentionSomeoneImportantForYou @Louis\\_Tomlinson\", \n",
    " \"\\#MentionSomeoneImportantForYou @Delta\\_Universe\"\n",
    "]\n",
    "[\n",
    " \"KathleenMariee\\_\", \n",
    " \"AhhlicksCruise\", \n",
    " \"itsravennn\\_cx\", \n",
    " \"kandykisses\\_13\", \n",
    " \"BMOLOGY\"\n",
    "]\n",
    "[\n",
    " \"MentionSomeOneImportantForYou\", \n",
    " \"MentionSomeoneImportantForYou\", \n",
    " \"MentionSomeoneImportantForYou\", \n",
    " \"MentionSomeoneImportantForYou\", \n",
    " \"MentionSomeoneImportantForYou\"\n",
    "]\n",
    "[\n",
    " \"\\u201c@KathleenMariee\\_:\", \n",
    " \"\\#MentionSomeOneImportantForYou\", \n",
    " \"@AhhlicksCruise\", \n",
    " \",\", \n",
    " \"@itsravennn\\_cx\"\n",
    "]</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, \\#MentionSomeoneImportantForYou dominates the hashtag\n",
    "      output. The output also provides a few commonly occurring screen names\n",
    "      that are worth <span class=\"keep-together\">investigating</span>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Tweets and Tweet Entities with Frequency Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Virtually all analysis boils down to the simple exercise of counting things on\n",
    "      some level, and much of what we'll be doing in this book is manipulating\n",
    "      data so that it can be counted and further manipulated in meaningful\n",
    "      ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From an empirical standpoint, counting observable things is the\n",
    "      starting point for just about everything, and thus the starting point\n",
    "      for any kind of statistical filtering or manipulation that strives to\n",
    "      find what may be a faint signal in noisy data. Whereas we just extracted\n",
    "      the first 5 items of each unranked list to get a feel for the data,\n",
    "      let's now take a closer look at what's in the data by computing a\n",
    "      frequency distribution and looking at the top 10 items in each\n",
    "      list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of Python 2.7, a <a class=\"ulink\" href=\"http://bit.ly/1a1l4tC\" target=\"\\_top\"><code class=\"literal\">collections</code></a> module is available that provides a counter that makes computing a\n",
    "      frequency distribution rather trivial. Example&#160;1.7, &#8220;Creating a basic frequency distribution from the words in\n",
    "        tweets&#8221; demonstrates how to use a <code class=\"literal\">Counter</code> to compute frequency distributions as\n",
    "      ranked lists of terms. Among the more compelling reasons for mining\n",
    "      Twitter data is to try to answer the question of what people are talking\n",
    "      about <span class=\"emphasis\"><em>right now</em></span>. One of the simplest techniques you\n",
    "      could apply to answer this question is basic frequency analysis, just as\n",
    "      we are performing here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1.7. Creating a basic frequency distribution from the words in tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('#pizza', 197), ('RT', 79), ('a', 61), ('for', 38), ('the', 37), ('#Pizza', 36), ('Pizza', 34), ('of', 30), ('#food', 30), ('and', 29)]\n",
      "[('DeliciouslyP', 6), ('Portuguese_chef', 5), ('ALIVE_EDM', 4), ('LatinosHadleigh', 4), ('comerae', 4), ('eventidop', 4), ('LolaLoMCR', 3), ('dogsndough', 3), ('YarosisNancy', 3), ('FoodeBook', 3)]\n",
      "[('pizza', 221), ('Pizza', 44), ('food', 30), ('OrlandPark', 21), ('foodie', 14), ('foodporn', 14), ('farinapetra', 11), ('pizzeria', 10), ('italianvilllapizza', 9), ('pasta', 9)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "for item in [words, screen_names, hashtags]:\n",
    "    c = Counter(item)\n",
    "    print(c.most_common()[:10]) # top 10\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some sample results from frequency analysis of\n",
    "      tweets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>[(u'\\#MentionSomeoneImportantForYou', 92), (u'RT', 34), (u'my', 10), \n",
    " (u',', 6), (u'@justinbieber', 6), (u'<3', 6), (u'My', 5), (u'and', 4), \n",
    " (u'I', 4), (u'te', 3)]\n",
    "\n",
    "[(u'justinbieber', 6), (u'Kid\\_Charliej', 2), (u'Cavillafuerte', 2), \n",
    " (u'touchmestyles\\_', 1), (u'aliceorr96', 1), (u'gymleeam', 1), (u'fienas', 1), \n",
    " (u'nayely\\_1D', 1), (u'angelchute', 1)]\n",
    "\n",
    "[(u'MentionSomeoneImportantForYou', 94), (u'mentionsomeoneimportantforyou', 3), \n",
    " (u'NoHomo', 1), (u'Love', 1), (u'MentionSomeOneImportantForYou', 1), \n",
    " (u'MyHeart', 1),  (u'bebesito', 1)]</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the frequency distribution is a map of key/value\n",
    "      pairs corresponding to terms and their frequencies, so let's make\n",
    "      reviewing the results a little easier on the eyes by emitting a tabular\n",
    "      format. You can install a package called <code class=\"literal\">prettytable</code> by typing <strong class=\"userinput\"><code>pip install prettytable</code></strong> in a terminal; this\n",
    "      package provides a convenient way to emit a fixed-width tabular format\n",
    "      that can be easily copied-and-pasted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example&#160;1.8, &#8220;Using prettytable to display tuples in a nice tabular\n",
    "          format&#8221; shows how to use it to display the\n",
    "      same results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1.8. Using prettytable to display tuples in a nice tabular format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "| Word   | Count |\n",
      "+--------+-------+\n",
      "| #pizza |   197 |\n",
      "| RT     |    79 |\n",
      "| a      |    61 |\n",
      "| for    |    38 |\n",
      "| the    |    37 |\n",
      "| #Pizza |    36 |\n",
      "| Pizza  |    34 |\n",
      "| of     |    30 |\n",
      "| #food  |    30 |\n",
      "| and    |    29 |\n",
      "+--------+-------+\n",
      "+-----------------+-------+\n",
      "| Screen Name     | Count |\n",
      "+-----------------+-------+\n",
      "| DeliciouslyP    |     6 |\n",
      "| Portuguese_chef |     5 |\n",
      "| ALIVE_EDM       |     4 |\n",
      "| LatinosHadleigh |     4 |\n",
      "| comerae         |     4 |\n",
      "| eventidop       |     4 |\n",
      "| LolaLoMCR       |     3 |\n",
      "| dogsndough      |     3 |\n",
      "| YarosisNancy    |     3 |\n",
      "| FoodeBook       |     3 |\n",
      "+-----------------+-------+\n",
      "+--------------------+-------+\n",
      "| Hashtag            | Count |\n",
      "+--------------------+-------+\n",
      "| pizza              |   221 |\n",
      "| Pizza              |    44 |\n",
      "| food               |    30 |\n",
      "| OrlandPark         |    21 |\n",
      "| foodie             |    14 |\n",
      "| foodporn           |    14 |\n",
      "| farinapetra        |    11 |\n",
      "| pizzeria           |    10 |\n",
      "| italianvilllapizza |     9 |\n",
      "| pasta              |     9 |\n",
      "+--------------------+-------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "for label, data in (('Word', words), \n",
    "                    ('Screen Name', screen_names), \n",
    "                    ('Hashtag', hashtags)):\n",
    "    pt = PrettyTable(field_names=[label, 'Count']) \n",
    "    c = Counter(data)\n",
    "    [ pt.add_row(kv) for kv in c.most_common()[:10] ]\n",
    "    pt.align[label], pt.align['Count'] = 'l', 'r' # Set column alignment\n",
    "    print(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br class=\"example-break\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results from Example&#160;1.8, &#8220;Using prettytable to display tuples in a nice tabular\n",
    "          format&#8221; are displayed as a\n",
    "      series of nicely formatted text-based tables that are easy to skim, as\n",
    "      the following output demonstrates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>+--------------------------------+-------+\n",
    "| Word                           | Count |\n",
    "+--------------------------------+-------+\n",
    "| \\#MentionSomeoneImportantForYou |    92 |\n",
    "| RT                             |    34 |\n",
    "| my                             |    10 |\n",
    "| ,                              |     6 |\n",
    "| @justinbieber                  |     6 |\n",
    "| &lt;3                          |     6 |\n",
    "| My                             |     5 |\n",
    "| and                            |     4 |\n",
    "| I                              |     4 |\n",
    "| te                             |     3 |\n",
    "+--------------------------------+-------+\n",
    "+----------------+-------+\n",
    "| Screen Name    | Count |\n",
    "+----------------+-------+\n",
    "| justinbieber   |     6 |\n",
    "| Kid\\_Charliej   |     2 |\n",
    "| Cavillafuerte  |     2 |\n",
    "| touchmestyles\\_ |     1 |\n",
    "| aliceorr96     |     1 |\n",
    "| gymleeam       |     1 |\n",
    "| fienas         |     1 |\n",
    "| nayely\\_1D      |     1 |\n",
    "| angelchute     |     1 |\n",
    "+----------------+-------+\n",
    "+-------------------------------+-------+\n",
    "| Hashtag                       | Count |\n",
    "+-------------------------------+-------+\n",
    "| MentionSomeoneImportantForYou |    94 |\n",
    "| mentionsomeoneimportantforyou |     3 |\n",
    "| NoHomo                        |     1 |\n",
    "| Love                          |     1 |\n",
    "| MentionSomeOneImportantForYou |     1 |\n",
    "| MyHeart                       |     1 |\n",
    "| bebesito                      |     1 |\n",
    "+-------------------------------+-------+</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick skim of the results reveals at least one marginally\n",
    "      surprising thing: Justin Bieber is high on the list of entities for this\n",
    "      small sample of data, and given his popularity with tweens on Twitter he\n",
    "      may very well have been the \"most important someone\" for this trending\n",
    "      topic, though the results here are inconclusive. The appearance of\n",
    "      <code class=\"literal\">&amp;lt;3</code> is also interesting because\n",
    "      it is an escaped form of <code class=\"literal\">&lt;3</code>, which\n",
    "      represents a heart shape (that's rotated 90 degrees, like other\n",
    "      emoticons and smileys) and is a common abbreviation for \"loves.\" Given\n",
    "      the nature of the query, it's not surprising to see a value like\n",
    "      <code class=\"literal\">&amp;lt;3</code>, although it may initially\n",
    "      seem like junk or noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the entities with a frequency greater than two are\n",
    "      interesting, the broader results are also revealing in other ways. For\n",
    "      example, \"RT\" was a very common token, implying that there were a\n",
    "      significant number of retweets (we'll investigate this observation\n",
    "      further in &#8220;Examining Patterns in Retweets&#8221;). Finally, as\n",
    "      might be expected, the \\#MentionSomeoneImportantForYou hashtag and a\n",
    "      couple of case-sensitive variations dominated the hashtags; a\n",
    "      data-processing takeaway is that it would be worthwhile to normalize\n",
    "      each word, screen name, and hashtag to lowercase when tabulating\n",
    "      frequencies since there will inevitably be variation in tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Lexical Diversity of Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A slightly more advanced measurement that involves calculating simple\n",
    "      frequencies and can be applied to unstructured text is a metric called\n",
    "      <span class=\"emphasis\"><em>lexical diversity</em></span>. Mathematically, this is an\n",
    "      expression of the number of <span class=\"emphasis\"><em>unique</em></span> tokens in the\n",
    "      text divided by the <span class=\"emphasis\"><em>total</em></span> number of tokens in the\n",
    "      text, which are both elementary yet important metrics in and of\n",
    "      themselves. Lexical diversity is an interesting concept in the area of\n",
    "      interpersonal communications because it provides a quantitative measure\n",
    "      for the diversity of an individual's or group's vocabulary. For example,\n",
    "      suppose you are listening to someone who repeatedly says \"and stuff\" to\n",
    "      broadly generalize information as opposed to providing specific examples\n",
    "      to reinforce points with more detail or clarity. Now, contrast that\n",
    "      speaker to someone else who seldom uses the word \"stuff\" to generalize\n",
    "      and instead reinforces points with concrete examples. The speaker who\n",
    "      repeatedly says \"and stuff\" would have a lower lexical diversity than\n",
    "      the speaker who uses a more diverse vocabulary, and chances are\n",
    "      reasonably good that you'd walk away from the conversation feeling as\n",
    "      though the speaker with the higher lexical diversity understands the\n",
    "      subject matter better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As applied to tweets or similar online communications, lexical\n",
    "      diversity can be worth considering as a primitive statistic for\n",
    "      answering a number of questions, such as how broad or narrow the subject\n",
    "      matter is that an individual or group discusses. Although an overall\n",
    "      assessment could be interesting, breaking down the analysis to specific\n",
    "      time periods could yield additional insight, as could comparing\n",
    "      different groups or individuals. For example, it would be interesting to\n",
    "      measure whether or not there is a significant difference between the\n",
    "      lexical diversity of two soft drink companies such as <a class=\"ulink\" href=\"http://bit.ly/1a1l5xR\" target=\"\\_top\">Coca-Cola</a> and <a class=\"ulink\" href=\"http://bit.ly/1a1l7pt\" target=\"\\_top\">Pepsi</a> as an entry point for\n",
    "      exploration if you were comparing the effectiveness of their social\n",
    "      media marketing campaigns on Twitter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a basic understanding of how to use a statistic like lexical\n",
    "      diversity to analyze textual content such as tweets, let's now compute\n",
    "      the lexical diversity for statuses, screen names, and hashtags for our\n",
    "      working data set, as shown in Example&#160;1.9, &#8220;Calculating lexical diversity for tweets&#8221;."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1.9. Calculating lexical diversity for tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4737235367372354\n",
      "0.6690140845070423\n",
      "0.4151624548736462\n",
      "14.925650557620818\n"
     ]
    }
   ],
   "source": [
    "# A function for computing lexical diversity\n",
    "def lexical_diversity(tokens):\n",
    "    return 1.0*len(set(tokens))/len(tokens) \n",
    "\n",
    "# A function for computing the average number of words per tweet\n",
    "def average_words(statuses):\n",
    "    total_words = sum([ len(s.split()) for s in statuses ]) \n",
    "    return 1.0*total_words/len(statuses)\n",
    "\n",
    "print(lexical_diversity(words))\n",
    "print(lexical_diversity(screen_names))\n",
    "print(lexical_diversity(hashtags))\n",
    "print(average_words(status_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of Example&#160;1.9, &#8220;Calculating lexical diversity for tweets&#8221;\n",
    "      follow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>0.67610619469\n",
    "0.955414012739\n",
    "0.0686274509804\n",
    "5.76530612245</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few observations worth considering in the\n",
    "      results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul class=\"itemizedlist\">\n",
    "              <li class=\"listitem\">\n",
    "                <p>The lexical diversity of the words in the text of the tweets\n",
    "            is around 0.67. One way to interpret that figure would be to say\n",
    "            that about two out of every three words is unique, or you might\n",
    "            say that each status update carries around 67% unique information.\n",
    "            Given that the average number of words in each tweet is around\n",
    "            six, that translates to about four unique words per tweet.\n",
    "            Intuition aligns with the data in that the nature of a\n",
    "            \\#MentionSomeoneImportantForYou trending hashtag is to solicit a\n",
    "            response that will probably be a few words long. In any event, a\n",
    "            value of 0.67 is on the high side for lexical diversity of\n",
    "            ordinary human communication, but given the nature of the data, it\n",
    "            seems very reasonable.</p>\n",
    "              </li>\n",
    "              <li class=\"listitem\">\n",
    "                <p>The lexical diversity of the screen names, however, is even higher, with a value\n",
    "            of 0.95, which means that about 19 out of 20 screen names\n",
    "            mentioned are unique. This observation also makes sense given that\n",
    "            many answers to the question will be a screen name, and that most\n",
    "            people won't be providing the same responses for the solicitous\n",
    "            hashtag.</p>\n",
    "              </li>\n",
    "              <li class=\"listitem\">\n",
    "                <p>The lexical diversity of the hashtags is extremely low at a value of around 0.068, implying\n",
    "            that very few values other than the \\#MentionSomeoneImportantForYou\n",
    "            hashtag appear multiple times in the results. Again, this makes\n",
    "            good sense given that most responses are short and that hashtags\n",
    "            really wouldn't make much sense to introduce as a response to the\n",
    "            prompt of mentioning someone important for you.</p>\n",
    "              </li>\n",
    "              <li class=\"listitem\">\n",
    "                <p>The average number of words per tweet is very low at a value\n",
    "            of just under 6, which makes sense given the nature of the\n",
    "            hashtag, which is designed to solicit short responses consisting\n",
    "            of just a few words.</p>\n",
    "              </li>\n",
    "            </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would be interesting at this point would be to zoom in on\n",
    "      some of the data and see if there were any common responses or other\n",
    "      insights that could come from a more qualitative analysis. Given an\n",
    "      average number of words per tweet as low as 6, it's unlikely that users\n",
    "      applied any abbreviations to stay within the 140 characters, so the\n",
    "      amount of noise for the data should be remarkably low, and additional\n",
    "      frequency analysis may reveal some fascinating things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining Patterns in Retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the user interface and many Twitter clients have long since adopted\n",
    "      the native Retweet API used to populate status values such as <code class=\"literal\">retweet\\_count</code> and <code class=\"literal\">retweeted\\_status</code>, some Twitter users may prefer to <a class=\"ulink\" href=\"http://bit.ly/1a1l7FZ\" target=\"\\_top\">quote a tweet</a>, which entails a workflow involving copying and pasting the text\n",
    "      and prepending \"RT @<span class=\"emphasis\"><em>username</em></span>\" or suffixing \"/via\n",
    "      @<span class=\"emphasis\"><em>username</em></span>\" to provide attribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote><div><strong>Note:</strong></div><p>When mining Twitter data, you'll probably want to both account\n",
    "        for the tweet metadata and use heuristics to analyze the 140\n",
    "        characters for conventions such as \"RT @<span class=\"emphasis\"><em>username</em></span>\"\n",
    "        or \"/via @<span class=\"emphasis\"><em>username</em></span>\" when considering retweets, in\n",
    "        order to maximize the efficacy of your analysis. See &#8220;Finding Users Who Have Retweeted a Status&#8221; for a more\n",
    "        detailed discussion on retweeting with Twitter's native Retweet API\n",
    "        versus \"quoting\" tweets and using conventions to apply\n",
    "        attribution.</p></blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good exercise at this point would be to further analyze the data\n",
    "      to determine if there was a particular tweet that was highly retweeted\n",
    "      or if there were just lots of \"one-off\" retweets. The approach we'll\n",
    "      take to find the most popular retweets is to simply iterate over each\n",
    "      status update and store out the retweet count, originator of the\n",
    "      retweet, and text of the retweet if the status update is a retweet.\n",
    "      Example&#160;1.10, &#8220;Finding the most popular retweets&#8221; demonstrates how to capture\n",
    "      these values with a list comprehension and sort by the retweet count to\n",
    "      display the top few results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1.10. Finding the most popular retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+----------------------------------------------------+\n",
      "| Count | Screen Name  | Text                                               |\n",
      "+-------+--------------+----------------------------------------------------+\n",
      "| 482   | lelepons     | RT @lelepons: No veo la hora de verte 😏#pizza      |\n",
      "| 36    | DeliciouslyP | RT @DeliciouslyP: I never knew how many            |\n",
      "|       |              | #glutenfree #pizza crust options there really are! |\n",
      "|       |              | It's fantastic! https://t.co/ojuoKCEthE https:/…   |\n",
      "| 36    | DeliciouslyP | RT @DeliciouslyP: I never knew how many            |\n",
      "|       |              | #glutenfree #pizza crust options there really are! |\n",
      "|       |              | It's fantastic! https://t.co/ojuoKCEthE https:/…   |\n",
      "| 36    | DeliciouslyP | RT @DeliciouslyP: I never knew how many            |\n",
      "|       |              | #glutenfree #pizza crust options there really are! |\n",
      "|       |              | It's fantastic! https://t.co/ojuoKCEthE https:/…   |\n",
      "| 36    | DeliciouslyP | RT @DeliciouslyP: I never knew how many            |\n",
      "|       |              | #glutenfree #pizza crust options there really are! |\n",
      "|       |              | It's fantastic! https://t.co/ojuoKCEthE https:/…   |\n",
      "+-------+--------------+----------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "retweets = [\n",
    "            # Store out a tuple of these three values ...\n",
    "            (status['retweet_count'], \n",
    "             status['retweeted_status']['user']['screen_name'],\n",
    "             status['text']) \n",
    "            \n",
    "\n",
    "    \n",
    "    # ... for each status ...\n",
    "            for status in statuses \n",
    "            \n",
    "            # ... so long as the status meets this condition.\n",
    "                if 'retweeted_status' in status\n",
    "           ]\n",
    "\n",
    "# Slice off the first 5 from the sorted results and display each item in the tuple\n",
    "\n",
    "pt = PrettyTable(field_names=['Count', 'Screen Name', 'Text'])\n",
    "[ pt.add_row(row) for row in sorted(retweets, reverse=True)[:5] ]\n",
    "pt.max_width['Text'] = 50\n",
    "pt.align= 'l'\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>+-------+----------------+----------------------------------------------------+\n",
    "| Count | Screen Name    | Text                                               |\n",
    "+-------+----------------+----------------------------------------------------+\n",
    "| 23    | hassanmusician | RT @hassanmusician: \\#MentionSomeoneImportantForYou |\n",
    "|       |                | God.                                               |\n",
    "| 21    | HSweethearts   | RT @HSweethearts: \\#MentionSomeoneImportantForYou   |\n",
    "|       |                | my high school sweetheart ❤                        |\n",
    "| 15    | LosAlejandro\\_  | RT @LosAlejandro\\_: ¿Nadie te menciono en           |\n",
    "|       |                | \"\\#MentionSomeoneImportantForYou\"? JAJAJAJAJAJAJAJA |\n",
    "|       |                | JAJAJAJAJAJAJAJAJAJAJAJAJAJAJAJAJAJAJAJA Ven, ...  |\n",
    "| 9     | SCOTTSUMME     | RT @SCOTTSUMME: \\#MentionSomeoneImportantForYou My  |\n",
    "|       |                | Mum. Shes loving, caring, strong, all in one. I    |\n",
    "|       |                | love her so much ❤❤❤❤                            |\n",
    "| 7     | degrassihaha   | RT @degrassihaha: \\#MentionSomeoneImportantForYou I |\n",
    "|       |                | can't put every Degrassi cast member, crew member, |\n",
    "|       |                | and writer in just one tweet....                   |\n",
    "+-------+----------------+----------------------------------------------------+</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"God\" tops the list, followed closely by \"my high school\n",
    "      sweetheart,\" and coming in at number four on the list is \"My Mum.\" None\n",
    "      of the top five items in the list correspond to Twitter user accounts,\n",
    "      although we might have suspected this (with the exception of\n",
    "      @justinbieber) from the previous analysis. Inspection of results further\n",
    "      down the list does reveal particular user mentions, but the sample we\n",
    "      have drawn from for this query is so small that no trends emerge.\n",
    "      Searching for a larger sample of results would likely yield some user\n",
    "      mentions with a frequency greater than one, which would be interesting\n",
    "      to further analyze. The possibilities for further analysis are pretty\n",
    "      open-ended, and by now, hopefully, you're itching to try out some custom\n",
    "      queries of your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote><div><strong>Note:</strong></div><p>Suggested exercises are at the end of this chapter. Be sure to\n",
    "        also check out Chapter&#160;9, <em>Twitter Cookbook</em> as a source of\n",
    "        inspiration: it includes more than two dozen recipes presented in a\n",
    "        cookbook-style format.</p></blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on, a subtlety worth noting is that it's quite\n",
    "      possible (and probable, given the relatively low frequencies of the\n",
    "      retweets observed in this section) that the original tweets that were\n",
    "      retweeted may not exist in our sample search results set. For example,\n",
    "      the most popular retweet in the sample results originated from a user\n",
    "      with a screen name of @hassanmusician and was retweeted 23 times.\n",
    "      However, closer inspection of the data reveals that we collected only 1\n",
    "      of the 23 retweets in our search results. Neither the original tweet nor\n",
    "      any of the other 22 retweets appears in the data set. This doesn't pose\n",
    "      any particular problems, although it might beg the question of who the\n",
    "      other 22 retweeters for this status were."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer to this kind of question is a valuable one because it\n",
    "      allows us to take content that represents a concept, such as \"God\" in\n",
    "      this case, and discover a group of other users who apparently share the\n",
    "      same sentiment or common interest. As previously mentioned, a handy way\n",
    "      to model data involving people and the things that they're interested in\n",
    "      is called an <span class=\"emphasis\"><em>interest graph</em></span>; this is the\n",
    "      primary data structure that supports analysis in Chapter&#160;7, <em>Mining GitHub: Inspecting Software Collaboration Habits, Building\n",
    "  Interest Graphs, and More</em>.\n",
    "      Interpretative speculation about these users could suggest that they are\n",
    "      spiritual or religious individuals, and further analysis of their\n",
    "      particular tweets might corroborate that inference. Example&#160;1.11, &#8220;Looking up users who have retweeted a status&#8221; shows how to find these individuals\n",
    "      with the <a class=\"ulink\" href=\"http://bit.ly/1a1l64H\" target=\"\\_top\"><code class=\"literal\">GET statuses/retweets/:id</code> API</a>."
   ]
  },
 


    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 5. Constructing convenient function calls"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from functools import partial\n",
      "\n",
      "pp = partial(json.dumps, indent=1)\n",
      "\n",
      "twitter_world_trends = partial(twitter_trends, twitter_api, WORLD_WOE_ID)\n",
      "\n",
      "print pp(twitter_world_trends())\n",
      "\n",
      "authenticated_twitter_search = partial(twitter_search, twitter_api)\n",
      "results = authenticated_twitter_search(\"iPhone\")\n",
      "print pp(results)\n",
      "\n",
      "authenticated_iphone_twitter_search = partial(authenticated_twitter_search, \"iPhone\")\n",
      "results = authenticated_iphone_twitter_search()\n",
      "print pp(results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 6. Saving and restoring JSON data with flat-text files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import io, json\n",
      "\n",
      "def save_json(filename, data):\n",
      "    with io.open('resources/ch09-twittercookbook/{0}.json'.format(filename), \n",
      "                 'w', encoding='utf-8') as f:\n",
      "        f.write(unicode(json.dumps(data, ensure_ascii=False)))\n",
      "\n",
      "def load_json(filename):\n",
      "    with io.open('resources/ch09-twittercookbook/{0}.json'.format(filename), \n",
      "                 encoding='utf-8') as f:\n",
      "        return f.read()\n",
      "\n",
      "# Sample usage\n",
      "\n",
      "q = 'CrossFit'\n",
      "\n",
      "twitter_api = oauth_login()\n",
      "results = twitter_search(twitter_api, q, max_results=10)\n",
      "\n",
      "save_json(q, results)\n",
      "results = load_json(q)\n",
      "\n",
      "print json.dumps(results, indent=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 7. Saving and accessing JSON data with MongoDB"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "import pymongo # pip install pymongo\n",
      "\n",
      "def save_to_mongo(data, mongo_db, mongo_db_coll, **mongo_conn_kw):\n",
      "    \n",
      "    # Connects to the MongoDB server running on \n",
      "    # localhost:27017 by default\n",
      "    \n",
      "    client = pymongo.MongoClient(**mongo_conn_kw)\n",
      "    \n",
      "    # Get a reference to a particular database\n",
      "    \n",
      "    db = client[mongo_db]\n",
      "    \n",
      "    # Reference a particular collection in the database\n",
      "    \n",
      "    coll = db[mongo_db_coll]\n",
      "    \n",
      "    # Perform a bulk insert and  return the IDs\n",
      "    \n",
      "    return coll.insert(data)\n",
      "\n",
      "def load_from_mongo(mongo_db, mongo_db_coll, return_cursor=False,\n",
      "                    criteria=None, projection=None, **mongo_conn_kw):\n",
      "    \n",
      "    # Optionally, use criteria and projection to limit the data that is \n",
      "    # returned as documented in \n",
      "    # http://docs.mongodb.org/manual/reference/method/db.collection.find/\n",
      "    \n",
      "    # Consider leveraging MongoDB's aggregations framework for more \n",
      "    # sophisticated queries.\n",
      "    \n",
      "    client = pymongo.MongoClient(**mongo_conn_kw)\n",
      "    db = client[mongo_db]\n",
      "    coll = db[mongo_db_coll]\n",
      "    \n",
      "    if criteria is None:\n",
      "        criteria = {}\n",
      "    \n",
      "    if projection is None:\n",
      "        cursor = coll.find(criteria)\n",
      "    else:\n",
      "        cursor = coll.find(criteria, projection)\n",
      "\n",
      "    # Returning a cursor is recommended for large amounts of data\n",
      "    \n",
      "    if return_cursor:\n",
      "        return cursor\n",
      "    else:\n",
      "        return [ item for item in cursor ]\n",
      "\n",
      "# Sample usage\n",
      "\n",
      "q = 'CrossFit'\n",
      "\n",
      "twitter_api = oauth_login()\n",
      "results = twitter_search(twitter_api, q, max_results=10)\n",
      "\n",
      "save_to_mongo(results, 'search_results', q)\n",
      "\n",
      "load_from_mongo('search_results', q)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 8. Sampling the Twitter firehose with the Streaming API"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Finding topics of interest by using the filtering capablities it offers.\n",
      "\n",
      "import sys\n",
      "import twitter\n",
      "\n",
      "# Query terms\n",
      "\n",
      "q = 'CrossFit' # Comma-separated list of terms\n",
      "\n",
      "print >> sys.stderr, 'Filtering the public timeline for track=\"%s\"' % (q,)\n",
      "sys.stderr.flush()\n",
      "\n",
      "# Returns an instance of twitter.Twitter\n",
      "twitter_api = oauth_login()\n",
      "\n",
      "# Reference the self.auth parameter\n",
      "twitter_stream = twitter.TwitterStream(auth=twitter_api.auth)\n",
      "\n",
      "# See https://dev.twitter.com/docs/streaming-apis\n",
      "stream = twitter_stream.statuses.filter(track=q)\n",
      "\n",
      "# For illustrative purposes, when all else fails, search for Justin Bieber\n",
      "# and something is sure to turn up (at least, on Twitter)\n",
      "\n",
      "for tweet in stream:\n",
      "    print tweet['text']\n",
      "    sys.stdout.flush()\n",
      "\n",
      "    # Save to a database in a particular collection"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 9. Collecting time-series data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import datetime\n",
      "import time\n",
      "import twitter\n",
      "\n",
      "def get_time_series_data(api_func, mongo_db_name, mongo_db_coll, \n",
      "                         secs_per_interval=60, max_intervals=15, **mongo_conn_kw):\n",
      "    \n",
      "    # Default settings of 15 intervals and 1 API call per interval ensure that \n",
      "    # you will not exceed the Twitter rate limit.\n",
      "    \n",
      "    interval = 0\n",
      "    \n",
      "    while True:\n",
      "    \n",
      "        # A timestamp of the form \"2013-06-14 12:52:07\"\n",
      "        now = str(datetime.datetime.now()).split(\".\")[0]\n",
      "    \n",
      "        ids = save_to_mongo(api_func(), mongo_db_name, mongo_db_coll + \"-\" + now)\n",
      "    \n",
      "        print >> sys.stderr, \"Write {0} trends\".format(len(ids))\n",
      "        print >> sys.stderr, \"Zzz...\"\n",
      "        print >> sys.stderr.flush()\n",
      "    \n",
      "        time.sleep(secs_per_interval) # seconds\n",
      "        interval += 1\n",
      "        \n",
      "        if interval >= 15:\n",
      "            break\n",
      "        \n",
      "# Sample usage\n",
      "\n",
      "get_time_series_data(twitter_world_trends, 'time-series', 'twitter_world_trends')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 10. Extracting tweet entities"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def extract_tweet_entities(statuses):\n",
      "    \n",
      "    # See https://dev.twitter.com/docs/tweet-entities for more details on tweet\n",
      "    # entities\n",
      "\n",
      "    if len(statuses) == 0:\n",
      "        return [], [], [], [], []\n",
      "    \n",
      "    screen_names = [ user_mention['screen_name'] \n",
      "                         for status in statuses\n",
      "                            for user_mention in status['entities']['user_mentions'] ]\n",
      "    \n",
      "    hashtags = [ hashtag['text'] \n",
      "                     for status in statuses \n",
      "                        for hashtag in status['entities']['hashtags'] ]\n",
      "\n",
      "    urls = [ url['expanded_url'] \n",
      "                     for status in statuses \n",
      "                        for url in status['entities']['urls'] ]\n",
      "    \n",
      "    symbols = [ symbol['text']\n",
      "                   for status in statuses\n",
      "                       for symbol in status['entities']['symbols'] ]\n",
      "               \n",
      "    # In some circumstances (such as search results), the media entity\n",
      "    # may not appear\n",
      "    if status['entities'].has_key('media'): \n",
      "        media = [ media['url'] \n",
      "                         for status in statuses  \n",
      "                            for media in status['entities']['media'] ]\n",
      "    else:\n",
      "        media = []\n",
      "\n",
      "    return screen_names, hashtags, urls, media, symbols\n",
      "\n",
      "# Sample usage\n",
      "\n",
      "q = 'CrossFit'\n",
      "\n",
      "statuses = twitter_search(twitter_api, q)\n",
      "\n",
      "screen_names, hashtags, urls, media, symbols = extract_tweet_entities(statuses)\n",
      "    \n",
      "# Explore the first five items for each...\n",
      "\n",
      "print json.dumps(screen_names[0:5], indent=1) \n",
      "print json.dumps(hashtags[0:5], indent=1)\n",
      "print json.dumps(urls[0:5], indent=1)\n",
      "print json.dumps(media[0:5], indent=1)\n",
      "print json.dumps(symbols[0:5], indent=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 11. Finding the most popular tweets in a collection of tweets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import twitter\n",
      "\n",
      "def find_popular_tweets(twitter_api, statuses, retweet_threshold=3):\n",
      "\n",
      "    # You could also consider using the favorite_count parameter as part of \n",
      "    # this  heuristic, possibly using it to provide an additional boost to \n",
      "    # popular tweets in a ranked formulation\n",
      "        \n",
      "    return [ status\n",
      "                for status in statuses \n",
      "                    if status['retweet_count'] > retweet_threshold ] \n",
      "    \n",
      "# Sample usage\n",
      "\n",
      "q = \"CrossFit\"\n",
      "\n",
      "twitter_api = oauth_login()\n",
      "search_results = twitter_search(twitter_api, q, max_results=200)\n",
      "\n",
      "popular_tweets = find_popular_tweets(twitter_api, search_results)\n",
      "\n",
      "for tweet in popular_tweets:\n",
      "    print tweet['text'], tweet['retweet_count']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 12. Finding the most popular tweet entities in a collection of tweets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import twitter\n",
      "from collections import Counter\n",
      "\n",
      "def get_common_tweet_entities(statuses, entity_threshold=3):\n",
      "\n",
      "    # Create a flat list of all tweet entities\n",
      "    tweet_entities = [  e\n",
      "                        for status in statuses\n",
      "                            for entity_type in extract_tweet_entities([status]) \n",
      "                                for e in entity_type \n",
      "                     ]\n",
      "\n",
      "    c = Counter(tweet_entities).most_common()\n",
      "\n",
      "    # Compute frequencies\n",
      "    return [ (k,v) \n",
      "             for (k,v) in c\n",
      "                 if v >= entity_threshold\n",
      "           ]\n",
      "\n",
      "# Sample usage\n",
      "\n",
      "q = 'CrossFit'\n",
      "\n",
      "twitter_api = oauth_login()\n",
      "search_results = twitter_search(twitter_api, q, max_results=100)\n",
      "common_entities = get_common_tweet_entities(search_results)\n",
      "\n",
      "print \"Most common tweet entities\"\n",
      "print common_entities"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 13. Tabulating frequency analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from prettytable import PrettyTable\n",
      "\n",
      "# Get some frequency data\n",
      "\n",
      "twitter_api = oauth_login()\n",
      "search_results = twitter_search(twitter_api, q, max_results=100)\n",
      "common_entities = get_common_tweet_entities(search_results)\n",
      "\n",
      "# Use PrettyTable to create a nice tabular display\n",
      "\n",
      "pt = PrettyTable(field_names=['Entity', 'Count']) \n",
      "[ pt.add_row(kv) for kv in common_entities ]\n",
      "pt.align['Entity'], pt.align['Count'] = 'l', 'r' # Set column alignment\n",
      "print pt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 14. Finding users who have retweeted a status"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import twitter\n",
      "\n",
      "twitter_api = oauth_login()\n",
      "\n",
      "print \"\"\"User IDs for retweeters of a tweet by @fperez_org\n",
      "that was retweeted by @SocialWebMining and that @jyeee then retweeted\n",
      "from @SocialWebMining's timeline\\n\"\"\"\n",
      "print twitter_api.statuses.retweeters.ids(_id=334188056905129984)['ids']\n",
      "print json.dumps(twitter_api.statuses.show(_id=334188056905129984), indent=1)\n",
      "print\n",
      "\n",
      "print \"@SocialWeb's retweet of @fperez_org's tweet\\n\"\n",
      "print twitter_api.statuses.retweeters.ids(_id=345723917798866944)['ids']\n",
      "print json.dumps(twitter_api.statuses.show(_id=345723917798866944), indent=1)\n",
      "print\n",
      "\n",
      "print \"@jyeee's retweet of @fperez_org's tweet\\n\"\n",
      "print twitter_api.statuses.retweeters.ids(_id=338835939172417537)['ids']\n",
      "print json.dumps(twitter_api.statuses.show(_id=338835939172417537), indent=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 15. Extracting a retweet's attribution"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "\n",
      "def get_rt_attributions(tweet):\n",
      "\n",
      "    # Regex adapted from Stack Overflow (http://bit.ly/1821y0J)\n",
      "\n",
      "    rt_patterns = re.compile(r\"(RT|via)((?:\\b\\W*@\\w+)+)\", re.IGNORECASE)\n",
      "    rt_attributions = []\n",
      "\n",
      "    # Inspect the tweet to see if it was produced with /statuses/retweet/:id.\n",
      "    # See https://dev.twitter.com/docs/api/1.1/get/statuses/retweets/%3Aid.\n",
      "    \n",
      "    if tweet.has_key('retweeted_status'):\n",
      "        attribution = tweet['retweeted_status']['user']['screen_name'].lower()\n",
      "        rt_attributions.append(attribution)\n",
      "\n",
      "    # Also, inspect the tweet for the presence of \"legacy\" retweet patterns\n",
      "    # such as \"RT\" and \"via\", which are still widely used for various reasons\n",
      "    # and potentially very useful. See https://dev.twitter.com/discussions/2847 \n",
      "    # and https://dev.twitter.com/discussions/1748 for some details on how/why.\n",
      "\n",
      "    try:\n",
      "        rt_attributions += [ \n",
      "                        mention.strip() \n",
      "                        for mention in rt_patterns.findall(tweet['text'])[0][1].split() \n",
      "                      ]\n",
      "    except IndexError, e:\n",
      "        pass\n",
      "\n",
      "    # Filter out any duplicates\n",
      "\n",
      "    return list(set([rta.strip(\"@\").lower() for rta in rt_attributions]))\n",
      "\n",
      "# Sample usage\n",
      "twitter_api = oauth_login()\n",
      "\n",
      "tweet = twitter_api.statuses.show(_id=214746575765913602)\n",
      "print get_rt_attributions(tweet)\n",
      "print\n",
      "tweet = twitter_api.statuses.show(_id=345723917798866944)\n",
      "print get_rt_attributions(tweet)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 16. Making robust Twitter requests"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import time\n",
      "from urllib2 import URLError\n",
      "from httplib import BadStatusLine\n",
      "import json\n",
      "import twitter\n",
      "\n",
      "def make_twitter_request(twitter_api_func, max_errors=10, *args, **kw): \n",
      "    \n",
      "    # A nested helper function that handles common HTTPErrors. Return an updated\n",
      "    # value for wait_period if the problem is a 500 level error. Block until the\n",
      "    # rate limit is reset if it's a rate limiting issue (429 error). Returns None\n",
      "    # for 401 and 404 errors, which requires special handling by the caller.\n",
      "    def handle_twitter_http_error(e, wait_period=2, sleep_when_rate_limited=True):\n",
      "    \n",
      "        if wait_period > 3600: # Seconds\n",
      "            print >> sys.stderr, 'Too many retries. Quitting.'\n",
      "            raise e\n",
      "    \n",
      "        # See https://dev.twitter.com/docs/error-codes-responses for common codes\n",
      "    \n",
      "        if e.e.code == 401:\n",
      "            print >> sys.stderr, 'Encountered 401 Error (Not Authorized)'\n",
      "            return None\n",
      "        elif e.e.code == 404:\n",
      "            print >> sys.stderr, 'Encountered 404 Error (Not Found)'\n",
      "            return None\n",
      "        elif e.e.code == 429: \n",
      "            print >> sys.stderr, 'Encountered 429 Error (Rate Limit Exceeded)'\n",
      "            if sleep_when_rate_limited:\n",
      "                print >> sys.stderr, \"Retrying in 15 minutes...ZzZ...\"\n",
      "                sys.stderr.flush()\n",
      "                time.sleep(60*15 + 5)\n",
      "                print >> sys.stderr, '...ZzZ...Awake now and trying again.'\n",
      "                return 2\n",
      "            else:\n",
      "                raise e # Caller must handle the rate limiting issue\n",
      "        elif e.e.code in (500, 502, 503, 504):\n",
      "            print >> sys.stderr, 'Encountered %i Error. Retrying in %i seconds' % \\\n",
      "                (e.e.code, wait_period)\n",
      "            time.sleep(wait_period)\n",
      "            wait_period *= 1.5\n",
      "            return wait_period\n",
      "        else:\n",
      "            raise e\n",
      "\n",
      "    # End of nested helper function\n",
      "    \n",
      "    wait_period = 2 \n",
      "    error_count = 0 \n",
      "\n",
      "    while True:\n",
      "        try:\n",
      "            return twitter_api_func(*args, **kw)\n",
      "        except twitter.api.TwitterHTTPError, e:\n",
      "            error_count = 0 \n",
      "            wait_period = handle_twitter_http_error(e, wait_period)\n",
      "            if wait_period is None:\n",
      "                return\n",
      "        except URLError, e:\n",
      "            error_count += 1\n",
      "            time.sleep(wait_period)\n",
      "            wait_period *= 1.5\n",
      "            print >> sys.stderr, \"URLError encountered. Continuing.\"\n",
      "            if error_count > max_errors:\n",
      "                print >> sys.stderr, \"Too many consecutive errors...bailing out.\"\n",
      "                raise\n",
      "        except BadStatusLine, e:\n",
      "            error_count += 1\n",
      "            time.sleep(wait_period)\n",
      "            wait_period *= 1.5\n",
      "            print >> sys.stderr, \"BadStatusLine encountered. Continuing.\"\n",
      "            if error_count > max_errors:\n",
      "                print >> sys.stderr, \"Too many consecutive errors...bailing out.\"\n",
      "                raise\n",
      "\n",
      "# Sample usage\n",
      "\n",
      "twitter_api = oauth_login()\n",
      "\n",
      "# See https://dev.twitter.com/docs/api/1.1/get/users/lookup for \n",
      "# twitter_api.users.lookup\n",
      "\n",
      "response = make_twitter_request(twitter_api.users.lookup, \n",
      "                                screen_name=\"SocialWebMining\")\n",
      "\n",
      "print json.dumps(response, indent=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 17. Resolving user profile information"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_user_profile(twitter_api, screen_names=None, user_ids=None):\n",
      "   \n",
      "    # Must have either screen_name or user_id (logical xor)\n",
      "    assert (screen_names != None) != (user_ids != None), \\\n",
      "    \"Must have screen_names or user_ids, but not both\"\n",
      "    \n",
      "    items_to_info = {}\n",
      "\n",
      "    items = screen_names or user_ids\n",
      "    \n",
      "    while len(items) > 0:\n",
      "\n",
      "        # Process 100 items at a time per the API specifications for /users/lookup.\n",
      "        # See https://dev.twitter.com/docs/api/1.1/get/users/lookup for details.\n",
      "        \n",
      "        items_str = ','.join([str(item) for item in items[:100]])\n",
      "        items = items[100:]\n",
      "\n",
      "        if screen_names:\n",
      "            response = make_twitter_request(twitter_api.users.lookup, \n",
      "                                            screen_name=items_str)\n",
      "        else: # user_ids\n",
      "            response = make_twitter_request(twitter_api.users.lookup, \n",
      "                                            user_id=items_str)\n",
      "    \n",
      "        for user_info in response:\n",
      "            if screen_names:\n",
      "                items_to_info[user_info['screen_name']] = user_info\n",
      "            else: # user_ids\n",
      "                items_to_info[user_info['id']] = user_info\n",
      "\n",
      "    return items_to_info\n",
      "\n",
      "# Sample usage\n",
      "\n",
      "twitter_api = oauth_login()\n",
      "\n",
      "print get_user_profile(twitter_api, screen_names=[\"SocialWebMining\", \"ptwobrussell\"]) \n",
      "#print get_user_profile(twitter_api, user_ids=[132373965])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 18. Extracting tweet entities from arbitrary text"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import twitter_text\n",
      "\n",
      "# Sample usage\n",
      "\n",
      "txt = \"RT @SocialWebMining Mining 1M+ Tweets About #Syria http://wp.me/p3QiJd-1I\"\n",
      "\n",
      "ex = twitter_text.Extractor(txt)\n",
      "\n",
      "print \"Screen Names:\", ex.extract_mentioned_screen_names_with_indices()\n",
      "print \"URLs:\", ex.extract_urls_with_indices()\n",
      "print \"Hashtags:\", ex.extract_hashtags_with_indices()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 19. Getting all friends or followers for a user"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from functools import partial\n",
      "from sys import maxint\n",
      "\n",
      "def get_friends_followers_ids(twitter_api, screen_name=None, user_id=None,\n",
      "                              friends_limit=maxint, followers_limit=maxint):\n",
      "    \n",
      "    # Must have either screen_name or user_id (logical xor)\n",
      "    assert (screen_name != None) != (user_id != None), \\\n",
      "    \"Must have screen_name or user_id, but not both\"\n",
      "    \n",
      "    # See https://dev.twitter.com/docs/api/1.1/get/friends/ids and\n",
      "    # https://dev.twitter.com/docs/api/1.1/get/followers/ids for details\n",
      "    # on API parameters\n",
      "    \n",
      "    get_friends_ids = partial(make_twitter_request, twitter_api.friends.ids, \n",
      "                              count=5000)\n",
      "    get_followers_ids = partial(make_twitter_request, twitter_api.followers.ids, \n",
      "                                count=5000)\n",
      "\n",
      "    friends_ids, followers_ids = [], []\n",
      "    \n",
      "    for twitter_api_func, limit, ids, label in [\n",
      "                    [get_friends_ids, friends_limit, friends_ids, \"friends\"], \n",
      "                    [get_followers_ids, followers_limit, followers_ids, \"followers\"]\n",
      "                ]:\n",
      "        \n",
      "        if limit == 0: continue\n",
      "        \n",
      "        cursor = -1\n",
      "        while cursor != 0:\n",
      "        \n",
      "            # Use make_twitter_request via the partially bound callable...\n",
      "            if screen_name: \n",
      "                response = twitter_api_func(screen_name=screen_name, cursor=cursor)\n",
      "            else: # user_id\n",
      "                response = twitter_api_func(user_id=user_id, cursor=cursor)\n",
      "\n",
      "            if response is not None:\n",
      "                ids += response['ids']\n",
      "                cursor = response['next_cursor']\n",
      "        \n",
      "            print >> sys.stderr, 'Fetched {0} total {1} ids for {2}'.format(len(ids), \n",
      "                                                    label, (user_id or screen_name))\n",
      "        \n",
      "            # XXX: You may want to store data during each iteration to provide an \n",
      "            # an additional layer of protection from exceptional circumstances\n",
      "        \n",
      "            if len(ids) >= limit or response is None:\n",
      "                break\n",
      "\n",
      "    # Do something useful with the IDs, like store them to disk...\n",
      "    return friends_ids[:friends_limit], followers_ids[:followers_limit]\n",
      "\n",
      "# Sample usage\n",
      "\n",
      "twitter_api = oauth_login()\n",
      "\n",
      "friends_ids, followers_ids = get_friends_followers_ids(twitter_api, \n",
      "                                                       screen_name=\"SocialWebMining\", \n",
      "                                                       friends_limit=10, \n",
      "                                                       followers_limit=10)\n",
      "\n",
      "print friends_ids\n",
      "print followers_ids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 20. Analyzing a user's friends and followers"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def setwise_friends_followers_analysis(screen_name, friends_ids, followers_ids):\n",
      "    \n",
      "    friends_ids, followers_ids = set(friends_ids), set(followers_ids)\n",
      "    \n",
      "    print '{0} is following {1}'.format(screen_name, len(friends_ids))\n",
      "\n",
      "    print '{0} is being followed by {1}'.format(screen_name, len(followers_ids))\n",
      "    \n",
      "    print '{0} of {1} are not following {2} back'.format(\n",
      "            len(friends_ids.difference(followers_ids)), \n",
      "            len(friends_ids), screen_name)\n",
      "    \n",
      "    print '{0} of {1} are not being followed back by {2}'.format(\n",
      "            len(followers_ids.difference(friends_ids)), \n",
      "            len(followers_ids), screen_name)\n",
      "    \n",
      "    print '{0} has {1} mutual friends'.format(\n",
      "            screen_name, len(friends_ids.intersection(followers_ids)))\n",
      "\n",
      "# Sample usage\n",
      "\n",
      "screen_name = \"ptwobrussell\"\n",
      "\n",
      "twitter_api = oauth_login()\n",
      "\n",
      "friends_ids, followers_ids = get_friends_followers_ids(twitter_api, \n",
      "                                                       screen_name=screen_name)\n",
      "setwise_friends_followers_analysis(screen_name, friends_ids, followers_ids)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 21. Harvesting a user's tweets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def harvest_user_timeline(twitter_api, screen_name=None, user_id=None, max_results=1000):\n",
      "     \n",
      "    assert (screen_name != None) != (user_id != None), \\\n",
      "    \"Must have screen_name or user_id, but not both\"    \n",
      "    \n",
      "    kw = {  # Keyword args for the Twitter API call\n",
      "        'count': 200,\n",
      "        'trim_user': 'true',\n",
      "        'include_rts' : 'true',\n",
      "        'since_id' : 1\n",
      "        }\n",
      "    \n",
      "    if screen_name:\n",
      "        kw['screen_name'] = screen_name\n",
      "    else:\n",
      "        kw['user_id'] = user_id\n",
      "        \n",
      "    max_pages = 16\n",
      "    results = []\n",
      "    \n",
      "    tweets = make_twitter_request(twitter_api.statuses.user_timeline, **kw)\n",
      "    \n",
      "    if tweets is None: # 401 (Not Authorized) - Need to bail out on loop entry\n",
      "        tweets = []\n",
      "        \n",
      "    results += tweets\n",
      "    \n",
      "    print >> sys.stderr, 'Fetched %i tweets' % len(tweets)\n",
      "    \n",
      "    page_num = 1\n",
      "    \n",
      "    # Many Twitter accounts have fewer than 200 tweets so you don't want to enter\n",
      "    # the loop and waste a precious request if max_results = 200.\n",
      "    \n",
      "    # Note: Analogous optimizations could be applied inside the loop to try and \n",
      "    # save requests. e.g. Don't make a third request if you have 287 tweets out of \n",
      "    # a possible 400 tweets after your second request. Twitter does do some \n",
      "    # post-filtering on censored and deleted tweets out of batches of 'count', though,\n",
      "    # so you can't strictly check for the number of results being 200. You might get\n",
      "    # back 198, for example, and still have many more tweets to go. If you have the\n",
      "    # total number of tweets for an account (by GET /users/lookup/), then you could \n",
      "    # simply use this value as a guide.\n",
      "    \n",
      "    if max_results == kw['count']:\n",
      "        page_num = max_pages # Prevent loop entry\n",
      "    \n",
      "    while page_num < max_pages and len(tweets) > 0 and len(results) < max_results:\n",
      "    \n",
      "        # Necessary for traversing the timeline in Twitter's v1.1 API:\n",
      "        # get the next query's max-id parameter to pass in.\n",
      "        # See https://dev.twitter.com/docs/working-with-timelines.\n",
      "        kw['max_id'] = min([ tweet['id'] for tweet in tweets]) - 1 \n",
      "    \n",
      "        tweets = make_twitter_request(twitter_api.statuses.user_timeline, **kw)\n",
      "        results += tweets\n",
      "\n",
      "        print >> sys.stderr, 'Fetched %i tweets' % (len(tweets),)\n",
      "    \n",
      "        page_num += 1\n",
      "        \n",
      "    print >> sys.stderr, 'Done fetching tweets'\n",
      "\n",
      "    return results[:max_results]\n",
      "    \n",
      "# Sample usage\n",
      "\n",
      "twitter_api = oauth_login()\n",
      "tweets = harvest_user_timeline(twitter_api, screen_name=\"SocialWebMining\", \\\n",
      "                               max_results=200)\n",
      "\n",
      "# Save to MongoDB with save_to_mongo or a local file with save_json..."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 22. Crawling a friendship graph"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def crawl_followers(twitter_api, screen_name, limit=1000000, depth=2):\n",
      "    \n",
      "    # Resolve the ID for screen_name and start working with IDs for consistency \n",
      "    # in storage\n",
      "\n",
      "    seed_id = str(twitter_api.users.show(screen_name=screen_name)['id'])\n",
      "    \n",
      "    _, next_queue = get_friends_followers_ids(twitter_api, user_id=seed_id, \n",
      "                                              friends_limit=0, followers_limit=limit)\n",
      "\n",
      "    # Store a seed_id => _follower_ids mapping in MongoDB\n",
      "    \n",
      "    save_to_mongo({'followers' : [ _id for _id in next_queue ]}, 'followers_crawl', \n",
      "                  '{0}-follower_ids'.format(seed_id))\n",
      "    \n",
      "    d = 1\n",
      "    while d < depth:\n",
      "        d += 1\n",
      "        (queue, next_queue) = (next_queue, [])\n",
      "        for fid in queue:\n",
      "            _, follower_ids = get_friends_followers_ids(twitter_api, user_id=fid, \n",
      "                                                     friends_limit=0, \n",
      "                                                     followers_limit=limit)\n",
      "            \n",
      "            # Store a fid => follower_ids mapping in MongoDB\n",
      "            save_to_mongo({'followers' : [ _id for _id in follower_ids ]}, \n",
      "                          'followers_crawl', '{0}-follower_ids'.format(fid))\n",
      "            \n",
      "            next_queue += follower_ids\n",
      "\n",
      "# Sample usage\n",
      "\n",
      "screen_name = \"timoreilly\"\n",
      "\n",
      "twitter_api = oauth_login()\n",
      "\n",
      "crawl_followers(twitter_api, screen_name, depth=1, limit=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 23. Analyzing tweet content"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def analyze_tweet_content(statuses):\n",
      "    \n",
      "    if len(statuses) == 0:\n",
      "        print \"No statuses to analyze\"\n",
      "        return\n",
      "    \n",
      "    # A nested helper function for computing lexical diversity\n",
      "    def lexical_diversity(tokens):\n",
      "        return 1.0*len(set(tokens))/len(tokens) \n",
      "    \n",
      "    # A nested helper function for computing the average number of words per tweet\n",
      "    def average_words(statuses):\n",
      "        total_words = sum([ len(s.split()) for s in statuses ]) \n",
      "        return 1.0*total_words/len(statuses)\n",
      "\n",
      "    status_texts = [ status['text'] for status in statuses ]\n",
      "    screen_names, hashtags, urls, media, _ = extract_tweet_entities(statuses)\n",
      "    \n",
      "    # Compute a collection of all words from all tweets\n",
      "    words = [ w \n",
      "          for t in status_texts \n",
      "              for w in t.split() ]\n",
      "    \n",
      "    print \"Lexical diversity (words):\", lexical_diversity(words)\n",
      "    print \"Lexical diversity (screen names):\", lexical_diversity(screen_names)\n",
      "    print \"Lexical diversity (hashtags):\", lexical_diversity(hashtags)\n",
      "    print \"Averge words per tweet:\", average_words(status_texts)\n",
      "\n",
      "    \n",
      "# Sample usage\n",
      "\n",
      "q = 'CrossFit'\n",
      "twitter_api = oauth_login()\n",
      "search_results = twitter_search(twitter_api, q)\n",
      "\n",
      "analyze_tweet_content(search_results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 24. Summarizing link targets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import json\n",
      "import nltk\n",
      "import numpy\n",
      "import requests\n",
      "from boilerpipe.extract import Extractor\n",
      "\n",
      "def summarize(url=None, html=None, n=100, cluster_threshold=5, top_sentences=5):\n",
      "\n",
      "    # Adapted from \"The Automatic Creation of Literature Abstracts\" by H.P. Luhn\n",
      "    #\n",
      "    # Parameters:\n",
      "    # * n  - Number of words to consider\n",
      "    # * cluster_threshold - Distance between words to consider\n",
      "    # * top_sentences - Number of sentences to return for a \"top n\" summary\n",
      "            \n",
      "    # Begin - nested helper function\n",
      "    def score_sentences(sentences, important_words):\n",
      "        scores = []\n",
      "        sentence_idx = -1\n",
      "    \n",
      "        for s in [nltk.tokenize.word_tokenize(s) for s in sentences]:\n",
      "    \n",
      "            sentence_idx += 1\n",
      "            word_idx = []\n",
      "    \n",
      "            # For each word in the word list...\n",
      "            for w in important_words:\n",
      "                try:\n",
      "                    # Compute an index for important words in each sentence\n",
      "    \n",
      "                    word_idx.append(s.index(w))\n",
      "                except ValueError, e: # w not in this particular sentence\n",
      "                    pass\n",
      "    \n",
      "            word_idx.sort()\n",
      "    \n",
      "            # It is possible that some sentences may not contain any important words\n",
      "            if len(word_idx)== 0: continue\n",
      "    \n",
      "            # Using the word index, compute clusters with a max distance threshold\n",
      "            # for any two consecutive words\n",
      "    \n",
      "            clusters = []\n",
      "            cluster = [word_idx[0]]\n",
      "            i = 1\n",
      "            while i < len(word_idx):\n",
      "                if word_idx[i] - word_idx[i - 1] < cluster_threshold:\n",
      "                    cluster.append(word_idx[i])\n",
      "                else:\n",
      "                    clusters.append(cluster[:])\n",
      "                    cluster = [word_idx[i]]\n",
      "                i += 1\n",
      "            clusters.append(cluster)\n",
      "    \n",
      "            # Score each cluster. The max score for any given cluster is the score \n",
      "            # for the sentence.\n",
      "    \n",
      "            max_cluster_score = 0\n",
      "            for c in clusters:\n",
      "                significant_words_in_cluster = len(c)\n",
      "                total_words_in_cluster = c[-1] - c[0] + 1\n",
      "                score = 1.0 * significant_words_in_cluster \\\n",
      "                    * significant_words_in_cluster / total_words_in_cluster\n",
      "    \n",
      "                if score > max_cluster_score:\n",
      "                    max_cluster_score = score\n",
      "    \n",
      "            scores.append((sentence_idx, score))\n",
      "    \n",
      "        return scores    \n",
      "    \n",
      "    # End - nested helper function\n",
      "    \n",
      "    extractor = Extractor(extractor='ArticleExtractor', url=url, html=html)\n",
      "\n",
      "    # It's entirely possible that this \"clean page\" will be a big mess. YMMV.\n",
      "    # The good news is that the summarize algorithm inherently accounts for handling\n",
      "    # a lot of this noise.\n",
      "\n",
      "    txt = extractor.getText()\n",
      "    \n",
      "    sentences = [s for s in nltk.tokenize.sent_tokenize(txt)]\n",
      "    normalized_sentences = [s.lower() for s in sentences]\n",
      "\n",
      "    words = [w.lower() for sentence in normalized_sentences for w in\n",
      "             nltk.tokenize.word_tokenize(sentence)]\n",
      "\n",
      "    fdist = nltk.FreqDist(words)\n",
      "\n",
      "    top_n_words = [w[0] for w in fdist.items() \n",
      "            if w[0] not in nltk.corpus.stopwords.words('english')][:n]\n",
      "\n",
      "    scored_sentences = score_sentences(normalized_sentences, top_n_words)\n",
      "\n",
      "    # Summarization Approach 1:\n",
      "    # Filter out nonsignificant sentences by using the average score plus a\n",
      "    # fraction of the std dev as a filter\n",
      "\n",
      "    avg = numpy.mean([s[1] for s in scored_sentences])\n",
      "    std = numpy.std([s[1] for s in scored_sentences])\n",
      "    mean_scored = [(sent_idx, score) for (sent_idx, score) in scored_sentences\n",
      "                   if score > avg + 0.5 * std]\n",
      "\n",
      "    # Summarization Approach 2:\n",
      "    # Another approach would be to return only the top N ranked sentences\n",
      "\n",
      "    top_n_scored = sorted(scored_sentences, key=lambda s: s[1])[-top_sentences:]\n",
      "    top_n_scored = sorted(top_n_scored, key=lambda s: s[0])\n",
      "\n",
      "    # Decorate the post object with summaries\n",
      "\n",
      "    return dict(top_n_summary=[sentences[idx] for (idx, score) in top_n_scored],\n",
      "                mean_scored_summary=[sentences[idx] for (idx, score) in mean_scored])\n",
      "\n",
      "# Sample usage\n",
      "\n",
      "sample_url = 'http://radar.oreilly.com/2013/06/phishing-in-facebooks-pond.html'\n",
      "summary = summarize(url=sample_url)\n",
      "\n",
      "# Alternatively, you can pass in HTML if you have it. Sometimes this approach may be\n",
      "# necessary if you encounter mysterious urllib2.BadStatusLine errors. Here's how\n",
      "# that would work:\n",
      "\n",
      "# sample_html = requests.get(sample_url).text\n",
      "# summary = summarize(html=sample_html)\n",
      "\n",
      "print \"-------------------------------------------------\"\n",
      "print \"                'Top N Summary'\"\n",
      "print \"-------------------------------------------------\"\n",
      "print \" \".join(summary['top_n_summary'])\n",
      "print\n",
      "print\n",
      "print \"-------------------------------------------------\"\n",
      "print \"             'Mean Scored' Summary\"\n",
      "print \"-------------------------------------------------\"\n",
      "print \" \".join(summary['mean_scored_summary'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },












  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"figure-title\">Figure&#160;1.6.&#160;A histogram of retweet frequencies</div>\n",
    "            <div class=\"figure-contents\">\n",
    "              <div class=\"mediaobject\">\n",
    "                <img alt=\"A histogram of retweet frequencies\" src=\"files/resources/sampler-images/images/mswb_0106.png\" />\n",
    "              </div>\n",
    "            </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for generating these histograms directly in IPython\n",
    "      Notebook is given in Examples 1.13 and 1.14. Taking some time to explore the\n",
    "      capabilities of matplotlib and other scientific computing tools is a\n",
    "      worthwhile investment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1.13. Generating histograms of words, screen names, and hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for label, data in (('Words', words), \n",
    "                    ('Screen Names', screen_names), \n",
    "                    ('Hashtags', hashtags)):\n",
    "\n",
    "    # Build a frequency map for each set of data\n",
    "    # and plot the values\n",
    "    c = Counter(data)\n",
    "    plt.hist(c.values())\n",
    "    \n",
    "    # Add a title and y-label ...\n",
    "    plt.title(label)\n",
    "    plt.ylabel(\"Number of items in bin\")\n",
    "    plt.xlabel(\"Bins (number of times an item appeared)\")\n",
    "    \n",
    "    # ... and display as a new figure\n",
    "    plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1.14. Generating a histogram of retweet counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using underscores while unpacking values in\n",
    "# a tuple is idiomatic for discarding them\n",
    "\n",
    "counts = [count for count, _, _ in retweets]\n",
    "\n",
    "plt.hist(counts)\n",
    "plt.title(\"Retweets\")\n",
    "plt.xlabel('Bins (number of times retweeted)')\n",
    "plt.ylabel('Number of tweets in bin')\n",
    "\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Closing Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter introduced Twitter as a successful technology platform that\n",
    "    has grown virally and become \"all the rage,\" given its ability to satisfy\n",
    "    some fundamental human desires relating to communication, curiosity, and\n",
    "    the self-organizing behavior that has emerged from its chaotic network\n",
    "    dynamics. The example code in this chapter got you up and running with\n",
    "    Twitter's API, illustrated how easy (and fun) it is to use Python to\n",
    "    interactively explore and analyze Twitter data, and provided some starting\n",
    "    templates that you can use for mining tweets. We started out the chapter\n",
    "    by learning how to create an authenticated connection and then progressed\n",
    "    through a series of examples that illustrated how to discover trending\n",
    "    topics for particular locales, how to search for tweets that might be\n",
    "    interesting, and how to analyze those tweets using some elementary but\n",
    "    effective techniques based on frequency analysis and simple statistics.\n",
    "    Even what seemed like a somewhat arbitrary trending topic turned out to\n",
    "    lead us down worthwhile paths with lots of possibilities for additional\n",
    "    analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote><div><strong>Note:</strong></div><p>Chapter&#160;9, <em>Twitter Cookbook</em> contains a number of Twitter\n",
    "      recipes covering a broad array of topics that range from tweet\n",
    "      harvesting and analysis to the effective use of storage for archiving\n",
    "      tweets to techniques for analyzing followers for insights.</p></blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the primary takeaways from this chapter from an analytical\n",
    "    standpoint is that counting is generally the first step to any kind of\n",
    "    meaningful quantitative analysis. Although basic frequency analysis is\n",
    "    simple, it is a powerful tool for your repertoire that shouldn’t be\n",
    "    overlooked just because it’s so obvious; besides, many other advanced\n",
    "    statistics depend on it. On the contrary, frequency analysis and measures\n",
    "    such as lexical diversity should be employed early and often, for\n",
    "    precisely the reason that doing so is so obvious and simple. Oftentimes,\n",
    "    but not always, the results from the simplest techniques can rival the\n",
    "    quality of those from more sophisticated analytics. With respect to data\n",
    "    in the Twitterverse, these modest techniques can usually get you quite a\n",
    "    long way toward answering the question, “What are people talking about\n",
    "    right now?” Now that's something we'd all like to know, isn't it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote><div><strong>Note:</strong></div><p>The source code outlined for this chapter and all other chapters\n",
    "      is available at <a class=\"ulink\" href=\"http://bit.ly/1a1kNqy\" target=\"\\_top\">GitHub</a> in a\n",
    "      convenient IPython Notebook format that you're highly encouraged to try\n",
    "      out from the comfort of your own web browser.</p></blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommended Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul class=\"itemizedlist\">\n",
    "            <li class=\"listitem\">\n",
    "              <p>Bookmark and spend some time reviewing <a class=\"ulink\" href=\"http://bit.ly/1a1kSKQ\" target=\"\\_top\">Twitter's API documentation</a>. In\n",
    "          particular, spend some time browsing the information on the <a class=\"ulink\" href=\"http://bit.ly/1a1kZ9i\" target=\"\\_top\">REST API</a> and <a class=\"ulink\" href=\"http://bit.ly/1a1kSL8\" target=\"\\_top\">platform objects</a>.</p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>If you haven't already, get comfortable working in <a class=\"ulink\" href=\"http://bit.ly/1a1laRY\" target=\"\\_top\">IPython</a> and <a class=\"ulink\" href=\"http://bit.ly/1a1laSf\" target=\"\\_top\">IPython Notebook</a> as a more\n",
    "          productive alternative to the traditional Python interpreter. Over\n",
    "          the course of your social web mining career, the saved time and\n",
    "          increased productivity will really start to add up.</p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>If you have a Twitter account with a nontrivial number of tweets, request your\n",
    "          historical tweet archive from your <a class=\"ulink\" href=\"http://bit.ly/1a1lb8D\" target=\"\\_top\">account settings</a> and analyze it.\n",
    "          The export of your account data includes files organized by time\n",
    "          period in a convenient JSON format. See the\n",
    "          <span class=\"emphasis\"><em>README.txt</em></span> file included in the downloaded\n",
    "          archive for more details. What are the most common terms that appear\n",
    "          in your tweets? Who do you retweet the most often? How many of your\n",
    "          tweets are retweeted (and why do you think this is the case)?</p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>Take some time to explore Twitter's REST API with its <a class=\"ulink\" href=\"http://bit.ly/1a1kWui\" target=\"\\_top\">developer console</a>. Although we\n",
    "          opted to dive in with the <code class=\"literal\">twitter</code>\n",
    "          Python package in a programmatic fashion in this chapter, the\n",
    "          console can be useful for exploring the API, the effects of\n",
    "          parameters, and more. The command-line tool <a class=\"ulink\" href=\"http://bit.ly/1a1kZq1\" target=\"\\_top\">Twurl</a> is another option to\n",
    "          consider if you prefer working in a terminal.</p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>Complete the exercise of determining whether there seems to be\n",
    "          a spiritual or religious affiliation for the users who retweeted the\n",
    "          status citing \"God\" as someone important to them, or follow the\n",
    "          workflow in this chapter for a trending topic or arbitrary search\n",
    "          query of your own choosing. Explore some of the <a class=\"ulink\" href=\"http://bit.ly/1a1l3pN\" target=\"\\_top\">advanced search features</a> that\n",
    "          are available for more precise querying.</p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>Explore <a class=\"ulink\" href=\"http://yhoo.it/1a1kZ9u\" target=\"\\_top\">Yahoo! GeoPlanet's\n",
    "          Where On Earth ID API</a> so that you can compare and contrast\n",
    "          trends from different locales.</p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>Take a closer look at <a class=\"ulink\" href=\"http://bit.ly/1a1l7Wv\" target=\"\\_top\"><code class=\"literal\">matplotlib</code></a> and learn how to create\n",
    "          <a class=\"ulink\" href=\"http://bit.ly/1a1lccP\" target=\"\\_top\">beautiful plots of 2D and 3D data\n",
    "          with IPython Notebook</a>.</p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>Explore and apply some of the exercises from Chapter&#160;9, <em>Twitter Cookbook</em>.</p>\n",
    "            </li>\n",
    "          </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following list of links from this chapter may be useful for\n",
    "    review:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul class=\"itemizedlist\">\n",
    "            <li class=\"listitem\">\n",
    "              <p>\n",
    "                <a class=\"ulink\" href=\"http://bit.ly/1a1lccP\" target=\"\\_top\">Beautiful plots of 2D and\n",
    "          3D data with IPython Notebook</a>\n",
    "              </p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>\n",
    "                <a class=\"ulink\" href=\"http://bit.ly/1a1kXyf\" target=\"\\_top\">IPython \"magic\n",
    "          functions\"</a>\n",
    "              </p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>\n",
    "                <a class=\"ulink\" href=\"http://bit.ly/1a1l2lJ\" target=\"\\_top\">json.org</a>\n",
    "              </p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>\n",
    "                <a class=\"ulink\" href=\"http://bit.ly/1a1l6BN\" target=\"\\_top\">PyLab</a>\n",
    "              </p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>\n",
    "                <a class=\"ulink\" href=\"http://bit.ly/1a1l1hy\" target=\"\\_top\">Python list\n",
    "          comprehensions</a>\n",
    "              </p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>\n",
    "                <a class=\"ulink\" href=\"http://bit.ly/1a1l1hy\" target=\"\\_top\">The official Python\n",
    "          tutorial</a>\n",
    "              </p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>\n",
    "                <a class=\"ulink\" href=\"http://bit.ly/1a1kZWN\" target=\"\\_top\">OAuth</a>\n",
    "              </p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>\n",
    "                <a class=\"ulink\" href=\"http://bit.ly/1a1kSKQ\" target=\"\\_top\">Twitter API\n",
    "          documentation</a>\n",
    "              </p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>\n",
    "                <a class=\"ulink\" href=\"http://bit.ly/1a1l2ly\" target=\"\\_top\">Twitter API Rate Limiting\n",
    "          in v1.1</a>\n",
    "              </p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>\n",
    "                <a class=\"ulink\" href=\"http://bit.ly/1a1kWui\" target=\"\\_top\">Twitter developer\n",
    "          console</a>\n",
    "              </p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>\n",
    "                <a class=\"ulink\" href=\"http://bit.ly/1a1kX1a\" target=\"\\_top\">Twitter Developer Rules of\n",
    "          the Road</a>\n",
    "              </p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>\n",
    "                <a class=\"ulink\" href=\"http://bit.ly/1a1kZWW\" target=\"\\_top\">Twitter's OAuth\n",
    "          documentation</a>\n",
    "              </p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>\n",
    "                <a class=\"ulink\" href=\"http://bit.ly/1a1l3pN\" target=\"\\_top\">Twitter Search API\n",
    "          operators</a>\n",
    "              </p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>\n",
    "                <a class=\"ulink\" href=\"http://bit.ly/1a1l1ya\" target=\"\\_top\">Twitter Streaming\n",
    "          API</a>\n",
    "              </p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>\n",
    "                <a class=\"ulink\" href=\"http://bit.ly/1a1kWKB\" target=\"\\_top\">Twitter terms of\n",
    "          service</a>\n",
    "              </p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>\n",
    "                <a class=\"ulink\" href=\"http://bit.ly/1a1kZq1\" target=\"\\_top\">Twurl</a>\n",
    "              </p>\n",
    "            </li>\n",
    "            <li class=\"listitem\">\n",
    "              <p>\n",
    "                <a class=\"ulink\" href=\"http://yhoo.it/1a1kZ9u\" target=\"\\_top\">Yahoo! GeoPlanet's Where\n",
    "          On Earth ID API</a>\n",
    "              </p>\n",
    "            </li>\n",
    "          </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "        <hr style=\"width: 100; align: left;\" />\n",
    "        <div class=\"footnote\">\n",
    "          <p><sup>[1] </sup>Although it's an implementation detail, it may be worth noting\n",
    "          that Twitter's v1.1 API still implements OAuth 1.0a, whereas many\n",
    "          other social web properties have since upgraded to OAuth 2.0.</p>\n",
    "        </div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
